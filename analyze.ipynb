{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Any, Dict\n",
    "import re\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from natsort import natsorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global information about each suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs  = {e: {} for e in Path(\"./out\").iterdir()}\n",
    "\n",
    "def add_entry_to_run(new_key: str, f: Callable[[Path, Dict[str, Any]], Any]) -> Dict[Path, Dict[str, Any]]:\n",
    "    global runs\n",
    "    for key, value in runs.items():\n",
    "        value.update({new_key: f(key, value)})\n",
    "\n",
    "add_entry_to_run(\"name\", lambda p, d: p.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time(p:Path, d):\n",
    "    file_path = p.rglob(\"klee/info\").__next__()\n",
    "    if file_path.exists():\n",
    "        with open(file_path, \"r\") as file:\n",
    "            res = re.search(r\"--max-time=(\\w*)\", file.read())\n",
    "            if res:\n",
    "                return res.group(1)\n",
    "    return None\n",
    "\n",
    "add_entry_to_run(\"time\", get_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per util information\n",
    "\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_entry_to_run(\"df\", lambda p, d: pd.DataFrame(columns=[e.name for e in p.iterdir() if e.is_dir()]))\n",
    "\n",
    "def add_entry_for_utils(key: str, f: Callable[[Path], Any]) -> None:\n",
    "    \"\"\"\n",
    "    Add entry for all utils\n",
    "\n",
    "    Paramenters:\n",
    "    key (str): key to add the new value at in the dataframe\n",
    "    f (Callable[[Path], Any]): function taking the path to the subfolder for the util and returning the appropriate value\n",
    "    \"\"\"\n",
    "\n",
    "    def adder(p: Path, d):\n",
    "        df = d[\"df\"]\n",
    "        res = {}\n",
    "        for util in df.columns:\n",
    "            path = p / util\n",
    "            if not path.exists():\n",
    "                raise Exception(f\"Path \\\"{util}\\\" does not exist\")\n",
    "            res[util] = f(path)\n",
    "        df.loc[key] = res\n",
    "        return df\n",
    "    add_entry_to_run(\"df\", adder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of errors according to KLEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_num_errors(util_path: Path) -> str:\n",
    "    file_path = util_path / \"klee\"\n",
    "    if file_path.exists():\n",
    "        return str(len(list(file_path.glob(\"*.err\"))))\n",
    "    return None\n",
    "\n",
    "add_entry_for_utils(\"num_errors\", read_num_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coverage according to KLEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_klee_csv(csv_name: str) -> Callable[[Path], str]:\n",
    "    def f(util_path: Path) -> str:\n",
    "        file_path = util_path / \"klee-stats.csv\"\n",
    "        if file_path.exists():\n",
    "            df = pd.read_csv(file_path)\n",
    "            return str(df[csv_name][0])\n",
    "        return None\n",
    "    return f\n",
    "\n",
    "add_entry_for_utils(\"klee_ICov\", read_klee_csv(\"ICov(%)\"))\n",
    "add_entry_for_utils(\"klee_BCov\", read_klee_csv(\"BCov(%)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coverage according to `gcov`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_gcov_cov(util_path: Path) -> str:\n",
    "    file_path = util_path / \"cov.txt\"\n",
    "    if file_path.exists():\n",
    "        with open(file_path, \"r\") as file:\n",
    "            res = re.search(r\"File '\\.\\./\\.\\./src/(\\w+)\\.c'\\nLines executed:(\\d?\\d\\d.\\d\\d)% of \\d+\", file.read())\n",
    "            if res:\n",
    "                return res.group(2)\n",
    "    return None\n",
    "\n",
    "add_entry_for_utils(\"gcov_cov\", read_gcov_cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots\n",
    "### Massaging `df`s together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             key      util   value                   DataFrame     time\n",
      "1095   klee_BCov      expr   22.34    out/coreutils-6.10-24h-2  1440min\n",
      "2079    gcov_cov     tsort   96.24       out/coreutils-6.10-6h   360min\n",
      "4049  num_errors   dirname    0.00  out/coreutils-6.10-10min-2    10min\n",
      "866     gcov_cov        df   78.34    out/coreutils-6.10-24h-2  1440min\n",
      "3718    gcov_cov        pr   76.96     out/coreutils-6.10-6h-2   360min\n",
      "3913  num_errors       pwd    0.00  out/coreutils-6.10-10min-2    10min\n",
      "1326   klee_ICov       seq   47.63    out/coreutils-6.10-10min    10min\n",
      "3118    gcov_cov    printf   95.24  out/coreutils-6.10-10min-3    10min\n",
      "2232   klee_ICov   pathchk   41.23        out/coreutils-6.10-4    60min\n",
      "446    klee_ICov     mknod   42.65        out/coreutils-6.10-3    60min\n",
      "1106   klee_ICov        ln   38.97    out/coreutils-6.10-10min    10min\n",
      "796    klee_ICov     mknod   42.65    out/coreutils-6.10-24h-2  1440min\n",
      "2535   klee_BCov  hostname   26.63          out/coreutils-6.10    60min\n",
      "3691  num_errors       tac    2.00     out/coreutils-6.10-6h-2   360min\n",
      "267   num_errors        od    1.00    out/coreutils-6.10-24h-3  1440min\n",
      "1381   klee_ICov  basename   37.36    out/coreutils-6.10-10min    10min\n",
      "3325  num_errors      sync    0.00      out/coreutils-6.10-24h  1440min\n",
      "2719   klee_BCov        od   40.23          out/coreutils-6.10    60min\n",
      "3232    gcov_cov    unlink  100.00      out/coreutils-6.10-24h  1440min\n",
      "947   num_errors        mv    0.00    out/coreutils-6.10-24h-2  1440min\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for k, v in runs.items():\n",
    "    df = v[\"df\"]\n",
    "    df = df.reset_index(names=\"key\")\n",
    "    df = df.melt(id_vars=\"key\", var_name=\"util\")\n",
    "    # .melt(id_vars=\"\")\n",
    "    df[\"DataFrame\"] = str(k)\n",
    "    df[\"time\"] = v[\"time\"]\n",
    "    dfs.append(df)\n",
    "\n",
    "combined_df = pd.concat(dfs)\n",
    "combined_df['value'] = combined_df['value'].astype(np.float64)\n",
    "combined_df = combined_df.dropna(subset=['value'])\n",
    "combined_df = combined_df.reset_index(drop=True)\n",
    "print(combined_df.sample(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots by coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage_df = combined_df.drop(columns=\"DataFrame\")\n",
    "keys = np.sort(coverage_df[\"key\"].unique())\n",
    "fig, axes = plt.subplots(nrows=len(keys), ncols=1, figsize=(10, 5*len(keys)), dpi=300)\n",
    "fig.suptitle(f\"Empirical Cumulative Distribution Function (ECDF)\", fontsize=20, y=0.99)\n",
    "for time in natsorted(coverage_df[\"time\"].unique()):\n",
    "    filtered_by_time_df = coverage_df[coverage_df[\"time\"] == time]\n",
    "    filtered_by_time_df = filtered_by_time_df.drop(columns=\"time\")\n",
    "    filtered_by_time_df = filtered_by_time_df.groupby([\"util\", \"key\"]).mean()\n",
    "    filtered_by_time_df = filtered_by_time_df.reset_index()\n",
    "    for key_i, key in enumerate(np.sort(keys)):\n",
    "        filtered_by_key_df = filtered_by_time_df[filtered_by_time_df['key'] == key]\n",
    "        axes[key_i].set_title(key)\n",
    "        sns.ecdfplot(y=\"value\", data=filtered_by_key_df, ax=axes[key_i], label=time)\n",
    "        axes[key_i].legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"plots/by-time.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gains by time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5040/1285088956.py:15: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df_keys = df_keys.groupby([\"time\"]).mean()\n",
      "/tmp/ipykernel_5040/1285088956.py:15: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df_keys = df_keys.groupby([\"time\"]).mean()\n",
      "/tmp/ipykernel_5040/1285088956.py:15: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df_keys = df_keys.groupby([\"time\"]).mean()\n",
      "/tmp/ipykernel_5040/1285088956.py:15: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df_keys = df_keys.groupby([\"time\"]).mean()\n"
     ]
    }
   ],
   "source": [
    "df = combined_df.drop(columns=[\"DataFrame\"])\n",
    "df = df.groupby([\"key\", \"time\", \"util\"]).mean()\n",
    "df = df.reset_index()\n",
    "keys = np.sort(df[\"key\"].unique())\n",
    "fig, axes = plt.subplots(nrows=len(keys), ncols=1, figsize=(5, 3*len(keys)), dpi=300)\n",
    "for i, key in enumerate(keys):\n",
    "    df_keys = df[df[\"key\"] == key]\n",
    "    df_keys = df_keys.drop(columns=\"key\")\n",
    "    order = natsorted(df_keys[\"time\"].unique())\n",
    "    df_keys['time'] = pd.Categorical(df_keys['time'], categories=order, ordered=True)\n",
    "    df_keys = df_keys.sort_values(['util', 'time'])\n",
    "    df_keys['difference'] = df_keys.groupby('util')['value'].diff()\n",
    "    df_keys = df_keys.reset_index()\n",
    "    df_keys = df_keys.drop(columns=[\"util\", \"value\"])\n",
    "    df_keys = df_keys.groupby([\"time\"]).mean()\n",
    "    df_keys = df_keys.reset_index()\n",
    "    df_keys['time'] = df_keys['time'].shift(1).astype(str) + ' - ' + df_keys['time'].astype(str)\n",
    "    df_keys = df_keys.dropna()\n",
    "    sns.barplot(data=df_keys, x=\"time\", y=\"difference\", ax=axes[i])\n",
    "    axes[i].set_ylabel(f\"average {key} gained\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"plots/gains_by_time.png\")\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots by util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with gcov_cov\n",
      "Done with klee_BCov\n",
      "Done with klee_ICov\n",
      "Done with num_errors\n"
     ]
    }
   ],
   "source": [
    "keys = np.sort(combined_df[\"key\"].unique())\n",
    "for key in keys:\n",
    "    filtered_by_key_df = combined_df[combined_df[\"key\"] == key]\n",
    "    utils = np.sort(filtered_by_key_df[\"util\"].unique())\n",
    "    fig, axes = plt.subplots(\n",
    "            nrows=int(np.ceil(len(utils)/5)),\n",
    "            ncols=5,\n",
    "            figsize=(25, len(utils)),\n",
    "            dpi=300\n",
    "        )\n",
    "    for i_util, util in enumerate(utils):\n",
    "        filtered_by_util_df = filtered_by_key_df[filtered_by_key_df['util'] == util]\n",
    "        ax = axes[i_util//5, i_util%5]\n",
    "        ax.set_title(f\"{util}\")\n",
    "        ax.set_ylabel(key)\n",
    "        order = natsorted(filtered_by_util_df[\"time\"].unique())\n",
    "        sns.boxplot(x=\"time\", y=\"value\", data=filtered_by_util_df, ax=ax, order=order)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots/by-util/{key}.png\")\n",
    "    plt.close()\n",
    "    print(f\"Done with {key}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
