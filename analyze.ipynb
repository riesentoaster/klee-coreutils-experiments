{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Any, Dict\n",
    "import re\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "from natsort import natsorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global information about each suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = {\n",
    "    run: {\"version\": version.name}\n",
    "    for version in Path(\"./out\").iterdir()\n",
    "    for run in version.iterdir()\n",
    "}\n",
    "\n",
    "\n",
    "def add_entry_to_run(\n",
    "    new_key: str, f: Callable[[Path, Dict[str, Any]], Any]\n",
    ") -> Dict[Path, Dict[str, Any]]:\n",
    "    global runs\n",
    "    for key, value in runs.items():\n",
    "        value.update({new_key: f(key, value)})\n",
    "\n",
    "\n",
    "add_entry_to_run(\"name\", lambda p, d: p.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time(p:Path, d):\n",
    "    file_path = p.rglob(\"klee/info\").__next__()\n",
    "    if file_path.exists():\n",
    "        with open(file_path, \"r\") as file:\n",
    "            res = re.search(r\"--max-time=(\\w*)\", file.read())\n",
    "            if res:\n",
    "                return res.group(1)\n",
    "    else:\n",
    "        print(f\"Error for {p}\")\n",
    "        return None\n",
    "\n",
    "add_entry_to_run(\"time\", get_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per util information\n",
    "\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_entry_to_run(\"df\", lambda p, d: pd.DataFrame(columns=[e.name for e in p.iterdir() if e.is_dir()]))\n",
    "\n",
    "def add_entry_for_utils(key: str, f: Callable[[Path], Any]) -> None:\n",
    "    \"\"\"\n",
    "    Add entry for all utils\n",
    "\n",
    "    Paramenters:\n",
    "    key (str): key to add the new value at in the dataframe\n",
    "    f (Callable[[Path], Any]): function taking the path to the subfolder for the util and returning the appropriate value\n",
    "    \"\"\"\n",
    "\n",
    "    def adder(p: Path, d):\n",
    "        df = d[\"df\"]\n",
    "        res = {}\n",
    "        for util in df.columns:\n",
    "            path = p / util\n",
    "            if not path.exists():\n",
    "                raise Exception(f\"Path \\\"{util}\\\" does not exist\")\n",
    "            res[util] = f(path)\n",
    "        df.loc[key] = res\n",
    "        return df\n",
    "    add_entry_to_run(\"df\", adder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of errors according to KLEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_num_errors(util_path: Path) -> str:\n",
    "    file_path = util_path / \"klee\"\n",
    "    if file_path.exists():\n",
    "        return str(len(list(file_path.glob(\"*.err\"))))\n",
    "    return None\n",
    "\n",
    "add_entry_for_utils(\"num_errors\", read_num_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coverage according to KLEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for ICov(%) – out/coreutils-8.25/1h-2/hostname\n",
      "Error for ICov(%) – out/coreutils-8.25/1h-2/setuidgid\n",
      "Error for ICov(%) – out/coreutils-8.25/1h/hostname\n",
      "Error for ICov(%) – out/coreutils-8.25/1h/setuidgid\n",
      "Error for BCov(%) – out/coreutils-8.25/1h-2/hostname\n",
      "Error for BCov(%) – out/coreutils-8.25/1h-2/setuidgid\n",
      "Error for BCov(%) – out/coreutils-8.25/1h/hostname\n",
      "Error for BCov(%) – out/coreutils-8.25/1h/setuidgid\n"
     ]
    }
   ],
   "source": [
    "def read_klee_csv(csv_name: str) -> Callable[[Path], str]:\n",
    "    def f(util_path: Path) -> str:\n",
    "        file_path = util_path / \"klee-stats.csv\"\n",
    "        if file_path.exists() and file_path.stat().st_size > 0:\n",
    "            df = pd.read_csv(file_path)\n",
    "            return str(df[csv_name][0])\n",
    "        else:\n",
    "            print(f\"Error for {csv_name} – {util_path}\")\n",
    "            return None\n",
    "    return f\n",
    "\n",
    "add_entry_for_utils(\"klee_ICov\", read_klee_csv(\"ICov(%)\"))\n",
    "add_entry_for_utils(\"klee_BCov\", read_klee_csv(\"BCov(%)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coverage according to `gcov`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_gcov_cov(util_path: Path) -> str:\n",
    "    file_path = util_path / \"cov.txt\"\n",
    "    if file_path.exists():\n",
    "        with open(file_path, \"r\") as file:\n",
    "            res = re.search(r\"File '(\\.\\./)?\\.\\./src/(\\w+)\\.c'\\nLines executed:(\\d?\\d\\d.\\d\\d)% of \\d+\", file.read())\n",
    "            if res:\n",
    "                return res.group(3)\n",
    "    return None\n",
    "\n",
    "add_entry_for_utils(\"gcov_cov\", read_gcov_cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots\n",
    "### Massaging `df`s together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             key      util   value      run     time         version\n",
      "3073   klee_ICov     split   44.77     1h-2    60min  coreutils-6.10\n",
      "1346   klee_ICov     rmdir   39.88     6h-3   360min  coreutils-6.10\n",
      "1065    gcov_cov    unlink  100.00     6h-3   360min  coreutils-6.10\n",
      "4811   klee_ICov  basename   37.36       1h    60min  coreutils-6.10\n",
      "147   num_errors      fold    0.00     1h-2    60min  coreutils-8.25\n",
      "4837    gcov_cov       tee   86.36       1h    60min  coreutils-6.10\n",
      "2505   klee_BCov      nice   27.71       6h   360min  coreutils-6.10\n",
      "3087    gcov_cov       tee   86.36     1h-2    60min  coreutils-6.10\n",
      "5128    gcov_cov      head   57.51  10min-2    10min  coreutils-6.10\n",
      "58      gcov_cov      sort   48.73     1h-2    60min  coreutils-8.25\n",
      "2255   klee_BCov    expand   32.07     1h-3    60min  coreutils-6.10\n",
      "1288  num_errors       yes    0.00     6h-3   360min  coreutils-6.10\n",
      "990     gcov_cov       tee   86.36    24h-3  1440min  coreutils-6.10\n",
      "5132    gcov_cov        wc   64.05  10min-2    10min  coreutils-6.10\n",
      "5001  num_errors     mkdir    1.00  10min-2    10min  coreutils-6.10\n",
      "187    klee_ICov      date   47.21     1h-2    60min  coreutils-8.25\n",
      "1517  num_errors      echo    0.00      24h  1440min  coreutils-6.10\n",
      "4243   klee_BCov      sort   26.60  10min-3    10min  coreutils-6.10\n",
      "2383    gcov_cov     pinky   55.67     1h-3    60min  coreutils-6.10\n",
      "222   num_errors        du    0.00     1h-2    60min  coreutils-8.25\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for k, v in runs.items():\n",
    "    df = v[\"df\"]\n",
    "    df = df.reset_index(names=\"key\")\n",
    "    df = df.melt(id_vars=\"key\", var_name=\"util\")\n",
    "    # .melt(id_vars=\"\")\n",
    "    df[\"run\"] = k.name\n",
    "    df[\"time\"] = v[\"time\"]\n",
    "    df[\"version\"] = v[\"version\"]\n",
    "    dfs.append(df)\n",
    "\n",
    "combined_df = pd.concat(dfs)\n",
    "combined_df['value'] = combined_df['value'].astype(np.float64)\n",
    "combined_df = combined_df.dropna(subset=['value'])\n",
    "combined_df = combined_df.reset_index(drop=True)\n",
    "print(combined_df.sample(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots by coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coverage_df = combined_df.drop(columns=\"run\")\n",
    "coverage_df = combined_df\n",
    "versions = natsorted(coverage_df[\"version\"].unique())\n",
    "keys = natsorted(coverage_df[\"key\"].unique())\n",
    "time_categories = natsorted(coverage_df[\"time\"].unique())\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=len(keys),\n",
    "    ncols=len(versions),\n",
    "    figsize=(10 * len(versions), 5 * len(keys)),\n",
    "    dpi=300,\n",
    ")\n",
    "fig.suptitle(f\"Empirical Cumulative Distribution Function (ECDF)\", fontsize=20, y=0.99)\n",
    "color_map = dict(zip(time_categories, sns.color_palette(n_colors=len(time_categories))))\n",
    "\n",
    "for version_i, version in enumerate(versions):\n",
    "    version_df = coverage_df[coverage_df[\"version\"] == version].drop(columns=\"version\")\n",
    "    for key_i, key in enumerate(keys):\n",
    "        key_df = version_df[version_df[\"key\"] == key].drop(columns=\"key\")\n",
    "        ax = axes[key_i, version_i]\n",
    "        ax.set_title(f\"{key} — {version}\")\n",
    "        for time in natsorted(key_df[\"time\"].unique()):\n",
    "            time_df = key_df[key_df[\"time\"] == time].drop(columns=\"time\")\n",
    "            for run_i, run in enumerate(time_df[\"run\"].unique()):\n",
    "                run_df = time_df[time_df[\"run\"] == run].drop(columns=\"run\")\n",
    "                sns.ecdfplot(\n",
    "                    y=\"value\",\n",
    "                    data=run_df,\n",
    "                    ax=ax,\n",
    "                    color=color_map[time],\n",
    "                    label=time if run_i == 0 else \"_nolegend_\",\n",
    "                )\n",
    "        ax.legend(title=\"Time\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"plots/ecdf.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gains by time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1666828/1018779821.py:16: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df_keys = df_keys.groupby([\"time\"]).mean()\n",
      "/tmp/ipykernel_1666828/1018779821.py:16: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df_keys = df_keys.groupby([\"time\"]).mean()\n",
      "/tmp/ipykernel_1666828/1018779821.py:16: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df_keys = df_keys.groupby([\"time\"]).mean()\n",
      "/tmp/ipykernel_1666828/1018779821.py:16: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df_keys = df_keys.groupby([\"time\"]).mean()\n"
     ]
    }
   ],
   "source": [
    "df = combined_df[combined_df[\"version\"] == \"coreutils-6.10\"].drop(\n",
    "    columns=[\"run\", \"version\"]\n",
    ")\n",
    "df = df.groupby([\"key\", \"time\", \"util\"], as_index=False).mean()\n",
    "keys = natsorted(df[\"key\"].unique())\n",
    "fig, axes = plt.subplots(nrows=len(keys), ncols=1, figsize=(5, 3 * len(keys)), dpi=300)\n",
    "for i, key in enumerate(keys):\n",
    "    df_keys = df[df[\"key\"] == key]\n",
    "    df_keys = df_keys.drop(columns=\"key\")\n",
    "    order = natsorted(df_keys[\"time\"].unique())\n",
    "    df_keys[\"time\"] = pd.Categorical(df_keys[\"time\"], categories=order, ordered=True)\n",
    "    df_keys = df_keys.sort_values([\"util\", \"time\"])\n",
    "    df_keys[\"difference\"] = df_keys.groupby(\"util\")[\"value\"].diff()\n",
    "    df_keys = df_keys.reset_index()\n",
    "    df_keys = df_keys.drop(columns=[\"util\", \"value\"])\n",
    "    df_keys = df_keys.groupby([\"time\"]).mean()\n",
    "    df_keys = df_keys.reset_index()\n",
    "    df_keys[\"time\"] = (\n",
    "        df_keys[\"time\"].shift(1).astype(str) + \" - \" + df_keys[\"time\"].astype(str)\n",
    "    )\n",
    "    df_keys = df_keys.dropna()\n",
    "    sns.barplot(data=df_keys, x=\"time\", y=\"difference\", ax=axes[i])\n",
    "    axes[i].set_ylabel(f\"average {key} gained\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"plots/gains_by_time.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots by util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with gcov_cov\n",
      "Done with klee_BCov\n",
      "Done with klee_ICov\n",
      "Done with num_errors\n"
     ]
    }
   ],
   "source": [
    "def paint_util(args):\n",
    "    key, util, key_df = args\n",
    "    util_df = key_df[key_df[\"util\"] == util].drop(columns=\"util\")\n",
    "    util_df = util_df.sort_values(by=\"version\")\n",
    "    times = natsorted(util_df['time'].unique())\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 6), dpi=300)\n",
    "    sns.stripplot(data=util_df, ax=ax, x='time', y=\"value\", hue=\"version\", order=times)\n",
    "    ax.set_title(f\"{util}\")\n",
    "    ax.set_ylabel(key)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f\"plots/{key}/{util}.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "for key in natsorted(combined_df[\"key\"].unique()):\n",
    "    key_df = combined_df[combined_df[\"key\"] == key].drop(columns=\"key\")\n",
    "    Path(f\"plots/{key}\").mkdir(exist_ok=True)\n",
    "    \n",
    "    utils = natsorted(key_df[\"util\"].unique())\n",
    "\n",
    "    with multiprocessing.Pool() as pool:\n",
    "        pool.map(paint_util, [(key, util, key_df) for util in utils])\n",
    "    \n",
    "    print(f\"Done with {key}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
