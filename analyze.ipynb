{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Callable, Any, Dict\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from natsort import natsorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global information about each suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs  = {e: {} for e in Path(\"./out\").iterdir()}\n",
    "\n",
    "def add_entry_to_run(new_key: str, f: Callable[[Path, Dict[str, Any]], Any]) -> Dict[Path, Dict[str, Any]]:\n",
    "    global runs\n",
    "    for key, value in runs.items():\n",
    "        value.update({new_key: f(key, value)})\n",
    "\n",
    "add_entry_to_run(\"name\", lambda p, d: p.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time(p:Path, d):\n",
    "    file_path = p.rglob(\"klee/info\").__next__()\n",
    "    if file_path.exists():\n",
    "        with open(file_path, \"r\") as file:\n",
    "            res = re.search(r\"--max-time=(\\w*)\", file.read())\n",
    "            if res:\n",
    "                return res.group(1)\n",
    "    return None\n",
    "\n",
    "add_entry_to_run(\"time\", get_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per util information\n",
    "\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_entry_to_run(\"df\", lambda p, d: pd.DataFrame(columns=[e.name for e in p.iterdir() if e.is_dir()]))\n",
    "\n",
    "def add_entry_for_utils(key: str, f: Callable[[Path], Any]) -> None:\n",
    "    \"\"\"\n",
    "    Add entry for all utils\n",
    "\n",
    "    Paramenters:\n",
    "    key (str): key to add the new value at in the dataframe\n",
    "    f (Callable[[Path], Any]): function taking the path to the subfolder for the util and returning the appropriate value\n",
    "    \"\"\"\n",
    "\n",
    "    def adder(p: Path, d):\n",
    "        df = d[\"df\"]\n",
    "        res = {}\n",
    "        for util in df.columns:\n",
    "            path = p / util\n",
    "            if not path.exists():\n",
    "                raise Exception(f\"Path \\\"{util}\\\" does not exist\")\n",
    "            res[util] = f(path)\n",
    "        df.loc[key] = res\n",
    "        return df\n",
    "    add_entry_to_run(\"df\", adder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of errors according to KLEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_num_errors(util_path: Path) -> str:\n",
    "    file_path = util_path / \"klee\"\n",
    "    if file_path.exists():\n",
    "        return str(len(list(file_path.glob(\"*.err\"))))\n",
    "    return None\n",
    "\n",
    "add_entry_for_utils(\"num_errors\", read_num_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coverage according to KLEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_klee_csv(csv_name: str) -> Callable[[Path], str]:\n",
    "    def f(util_path: Path) -> str:\n",
    "        file_path = util_path / \"klee-stats.csv\"\n",
    "        if file_path.exists():\n",
    "            df = pd.read_csv(file_path)\n",
    "            return str(df[csv_name][0])\n",
    "        return None\n",
    "    return f\n",
    "\n",
    "add_entry_for_utils(\"klee_ICov\", read_klee_csv(\"ICov(%)\"))\n",
    "add_entry_for_utils(\"klee_BCov\", read_klee_csv(\"BCov(%)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coverage according to `gcov`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_gcov_cov(util_path: Path) -> str:\n",
    "    file_path = util_path / \"cov.txt\"\n",
    "    if file_path.exists():\n",
    "        with open(file_path, \"r\") as file:\n",
    "            res = re.search(r\"File '\\.\\./\\.\\./src/(\\w+)\\.c'\\nLines executed:(\\d?\\d\\d.\\d\\d)% of \\d+\", file.read())\n",
    "            if res:\n",
    "                return res.group(2)\n",
    "    return None\n",
    "\n",
    "add_entry_for_utils(\"gcov_cov\", read_gcov_cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots\n",
    "### Massaging `df`s together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           key      util  value                 DataFrame     time\n",
      "0   num_errors        ln   0.00  out/coreutils-6.10-24h-3  1440min\n",
      "1    klee_ICov        ln  45.43  out/coreutils-6.10-24h-3  1440min\n",
      "2    klee_BCov        ln  33.77  out/coreutils-6.10-24h-3  1440min\n",
      "3     gcov_cov        ln  86.08  out/coreutils-6.10-24h-3  1440min\n",
      "4   num_errors     shred   7.00  out/coreutils-6.10-24h-3  1440min\n",
      "5    klee_ICov     shred  44.97  out/coreutils-6.10-24h-3  1440min\n",
      "6    klee_BCov     shred  32.62  out/coreutils-6.10-24h-3  1440min\n",
      "7     gcov_cov     shred  68.53  out/coreutils-6.10-24h-3  1440min\n",
      "8   num_errors       pwd   0.00  out/coreutils-6.10-24h-3  1440min\n",
      "9    klee_ICov       pwd  34.95  out/coreutils-6.10-24h-3  1440min\n",
      "10   klee_BCov       pwd  23.03  out/coreutils-6.10-24h-3  1440min\n",
      "11    gcov_cov       pwd  20.34  out/coreutils-6.10-24h-3  1440min\n",
      "12  num_errors  unexpand   1.00  out/coreutils-6.10-24h-3  1440min\n",
      "13   klee_ICov  unexpand  44.64  out/coreutils-6.10-24h-3  1440min\n",
      "14   klee_BCov  unexpand  32.58  out/coreutils-6.10-24h-3  1440min\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for k, v in runs.items():\n",
    "    df = v[\"df\"]\n",
    "    df = df.reset_index(names=\"key\")\n",
    "    df = df.melt(id_vars=\"key\", var_name=\"util\")\n",
    "    # .melt(id_vars=\"\")\n",
    "    df[\"DataFrame\"] = str(k)\n",
    "    df[\"time\"] = v[\"time\"]\n",
    "    dfs.append(df)\n",
    "\n",
    "combined_df = pd.concat(dfs)\n",
    "combined_df['value'] = combined_df['value'].astype(np.float64)\n",
    "combined_df = combined_df.dropna(subset=['value'])\n",
    "combined_df = combined_df.reset_index(drop=True)\n",
    "print(combined_df.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots by util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with base64\n",
      "Done with basename\n",
      "Done with cat\n",
      "Done with chcon\n",
      "Done with chgrp\n",
      "Done with chmod\n",
      "Done with chown\n",
      "Done with chroot\n",
      "Done with cksum\n",
      "Done with comm\n",
      "Done with cp\n",
      "Done with csplit\n",
      "Done with cut\n",
      "Done with date\n",
      "Done with dd\n",
      "Done with df\n",
      "Done with dircolors\n",
      "Done with dirname\n",
      "Done with du\n",
      "Done with echo\n",
      "Done with env\n",
      "Done with expand\n",
      "Done with expr\n",
      "Done with factor\n",
      "Done with false\n",
      "Done with fmt\n",
      "Done with fold\n",
      "Done with ginstall\n",
      "Done with head\n",
      "Done with hostid\n",
      "Done with hostname\n",
      "Done with id\n",
      "Done with join\n",
      "Done with kill\n",
      "Done with link\n",
      "Done with ln\n",
      "Done with logname\n",
      "Done with ls\n",
      "Done with md5sum\n",
      "Done with mkdir\n",
      "Done with mkfifo\n",
      "Done with mknod\n",
      "Done with mktemp\n",
      "Done with mv\n",
      "Done with nice\n",
      "Done with nl\n",
      "Done with nohup\n",
      "Done with od\n",
      "Done with paste\n",
      "Done with pathchk\n",
      "Done with pinky\n",
      "Done with pr\n",
      "Done with printenv\n",
      "Done with printf\n",
      "Done with ptx\n",
      "Done with pwd\n",
      "Done with readlink\n",
      "Done with rm\n",
      "Done with rmdir\n",
      "Done with runcon\n",
      "Done with seq\n",
      "Done with setuidgid\n",
      "Done with shred\n",
      "Done with shuf\n",
      "Done with sleep\n",
      "Done with sort\n",
      "Done with split\n",
      "Done with stat\n",
      "Done with stty\n",
      "Done with sum\n",
      "Done with sync\n",
      "Done with tac\n",
      "Done with tail\n",
      "Done with tee\n",
      "Done with touch\n",
      "Done with tr\n",
      "Done with tsort\n",
      "Done with tty\n",
      "Done with uname\n",
      "Done with unexpand\n",
      "Done with uniq\n",
      "Done with unlink\n",
      "Done with uptime\n",
      "Done with users\n",
      "Done with wc\n",
      "Done with who\n",
      "Done with whoami\n",
      "Done with yes\n"
     ]
    }
   ],
   "source": [
    "for util in np.sort(combined_df[\"util\"].unique()):\n",
    "    filtered_by_util_df = combined_df[combined_df['util'] == util]\n",
    "    keys = combined_df[\"key\"].unique()\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=len(keys), figsize=(5*len(keys), 5), dpi=300)\n",
    "    fig.suptitle(f\"Plots for util \\\"{util}\\\"\", fontsize=20)\n",
    "    for i, key in enumerate(keys):\n",
    "        filtered_by_key_df = filtered_by_util_df[filtered_by_util_df['key'] == key]\n",
    "        axes[i].set_title(key)\n",
    "        order = natsorted(filtered_by_key_df[\"time\"].unique())\n",
    "        sns.boxplot(x=\"time\", y=\"value\", data=filtered_by_key_df, ax=axes[i], order=order)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots/by-util/{util}.png\")\n",
    "    plt.close()\n",
    "    print(f\"Done with {util}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots by coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage_df = combined_df.drop(columns=\"DataFrame\")\n",
    "keys = coverage_df[\"key\"].unique()\n",
    "fig, axes = plt.subplots(nrows=len(keys), ncols=1, figsize=(10, 5*len(keys)), dpi=300)\n",
    "fig.suptitle(f\"Empirical Cumulative Distribution Function (ECDF)\", fontsize=20, y=0.99)\n",
    "for time in natsorted(coverage_df[\"time\"].unique()):\n",
    "    filtered_by_time_df = coverage_df[coverage_df[\"time\"] == time]\n",
    "    filtered_by_time_df = filtered_by_time_df.drop(columns=\"time\")\n",
    "    filtered_by_time_df = filtered_by_time_df.groupby([\"util\", \"key\"]).mean()\n",
    "    filtered_by_time_df = filtered_by_time_df.reset_index()\n",
    "    for key_i, key in enumerate(np.sort(keys)):\n",
    "        filtered_by_key_df = filtered_by_time_df[filtered_by_time_df['key'] == key]\n",
    "        axes[key_i].set_title(f\"{key} for {time}\")\n",
    "        sns.ecdfplot(y=\"value\", data=filtered_by_key_df, ax=axes[key_i], label=time)\n",
    "        axes[key_i].legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"plots/by-time.png\")\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
