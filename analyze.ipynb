{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Any, Dict\n",
    "import re\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from natsort import natsorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global information about each suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs  = {e: {} for e in Path(\"./out\").iterdir()}\n",
    "\n",
    "def add_entry_to_run(new_key: str, f: Callable[[Path, Dict[str, Any]], Any]) -> Dict[Path, Dict[str, Any]]:\n",
    "    global runs\n",
    "    for key, value in runs.items():\n",
    "        value.update({new_key: f(key, value)})\n",
    "\n",
    "add_entry_to_run(\"name\", lambda p, d: p.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time(p:Path, d):\n",
    "    file_path = p.rglob(\"klee/info\").__next__()\n",
    "    if file_path.exists():\n",
    "        with open(file_path, \"r\") as file:\n",
    "            res = re.search(r\"--max-time=(\\w*)\", file.read())\n",
    "            if res:\n",
    "                return res.group(1)\n",
    "    return None\n",
    "\n",
    "add_entry_to_run(\"time\", get_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per util information\n",
    "\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_entry_to_run(\"df\", lambda p, d: pd.DataFrame(columns=[e.name for e in p.iterdir() if e.is_dir()]))\n",
    "\n",
    "def add_entry_for_utils(key: str, f: Callable[[Path], Any]) -> None:\n",
    "    \"\"\"\n",
    "    Add entry for all utils\n",
    "\n",
    "    Paramenters:\n",
    "    key (str): key to add the new value at in the dataframe\n",
    "    f (Callable[[Path], Any]): function taking the path to the subfolder for the util and returning the appropriate value\n",
    "    \"\"\"\n",
    "\n",
    "    def adder(p: Path, d):\n",
    "        df = d[\"df\"]\n",
    "        res = {}\n",
    "        for util in df.columns:\n",
    "            path = p / util\n",
    "            if not path.exists():\n",
    "                raise Exception(f\"Path \\\"{util}\\\" does not exist\")\n",
    "            res[util] = f(path)\n",
    "        df.loc[key] = res\n",
    "        return df\n",
    "    add_entry_to_run(\"df\", adder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of errors according to KLEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_num_errors(util_path: Path) -> str:\n",
    "    file_path = util_path / \"klee\"\n",
    "    if file_path.exists():\n",
    "        return str(len(list(file_path.glob(\"*.err\"))))\n",
    "    return None\n",
    "\n",
    "add_entry_for_utils(\"num_errors\", read_num_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coverage according to KLEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_klee_csv(csv_name: str) -> Callable[[Path], str]:\n",
    "    def f(util_path: Path) -> str:\n",
    "        file_path = util_path / \"klee-stats.csv\"\n",
    "        if file_path.exists():\n",
    "            df = pd.read_csv(file_path)\n",
    "            return str(df[csv_name][0])\n",
    "        return None\n",
    "    return f\n",
    "\n",
    "add_entry_for_utils(\"klee_ICov\", read_klee_csv(\"ICov(%)\"))\n",
    "add_entry_for_utils(\"klee_BCov\", read_klee_csv(\"BCov(%)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coverage according to `gcov`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_gcov_cov(util_path: Path) -> str:\n",
    "    file_path = util_path / \"cov.txt\"\n",
    "    if file_path.exists():\n",
    "        with open(file_path, \"r\") as file:\n",
    "            res = re.search(r\"File '\\.\\./\\.\\./src/(\\w+)\\.c'\\nLines executed:(\\d?\\d\\d.\\d\\d)% of \\d+\", file.read())\n",
    "            if res:\n",
    "                return res.group(2)\n",
    "    return None\n",
    "\n",
    "add_entry_for_utils(\"gcov_cov\", read_gcov_cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots\n",
    "### Massaging `df`s together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             key      util   value                   DataFrame     time\n",
      "2019   klee_BCov    csplit   19.16        out/coreutils-6.10-4    60min\n",
      "2108  num_errors       pwd    0.00          out/coreutils-6.10    60min\n",
      "1161    gcov_cov        df   72.40    out/coreutils-6.10-10min    10min\n",
      "2815    gcov_cov  unexpand   91.76      out/coreutils-6.10-24h  1440min\n",
      "477     gcov_cov       sum   90.36        out/coreutils-6.10-3    60min\n",
      "2063    gcov_cov     rmdir   81.03        out/coreutils-6.10-4    60min\n",
      "3040  num_errors      head    2.00      out/coreutils-6.10-24h  1440min\n",
      "1421   klee_ICov      join   42.32        out/coreutils-6.10-2    60min\n",
      "1631    gcov_cov        du   83.51        out/coreutils-6.10-2    60min\n",
      "3365    gcov_cov        od   84.53  out/coreutils-6.10-10min-2    10min\n",
      "547    klee_ICov      comm   40.50        out/coreutils-6.10-3    60min\n",
      "2332  num_errors     nohup    0.00          out/coreutils-6.10    60min\n",
      "2245   klee_ICov   dirname   37.01          out/coreutils-6.10    60min\n",
      "1754  num_errors     shred    1.00        out/coreutils-6.10-4    60min\n",
      "1215   klee_ICov      uniq   41.79    out/coreutils-6.10-10min    10min\n",
      "1825    gcov_cov  readlink  100.00        out/coreutils-6.10-4    60min\n",
      "1157    gcov_cov       ptx   55.95    out/coreutils-6.10-10min    10min\n",
      "3094    gcov_cov     chgrp   96.47      out/coreutils-6.10-24h  1440min\n",
      "673    klee_ICov       cat   41.20        out/coreutils-6.10-3    60min\n",
      "94     klee_BCov       fmt   32.54    out/coreutils-6.10-24h-3  1440min\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for k, v in runs.items():\n",
    "    df = v[\"df\"]\n",
    "    df = df.reset_index(names=\"key\")\n",
    "    df = df.melt(id_vars=\"key\", var_name=\"util\")\n",
    "    # .melt(id_vars=\"\")\n",
    "    df[\"DataFrame\"] = str(k)\n",
    "    df[\"time\"] = v[\"time\"]\n",
    "    dfs.append(df)\n",
    "\n",
    "combined_df = pd.concat(dfs)\n",
    "combined_df['value'] = combined_df['value'].astype(np.float64)\n",
    "combined_df = combined_df.dropna(subset=['value'])\n",
    "combined_df = combined_df.reset_index(drop=True)\n",
    "print(combined_df.sample(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots by coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage_df = combined_df.drop(columns=\"DataFrame\")\n",
    "keys = np.sort(coverage_df[\"key\"].unique())\n",
    "fig, axes = plt.subplots(nrows=len(keys), ncols=1, figsize=(10, 5*len(keys)), dpi=300)\n",
    "fig.suptitle(f\"Empirical Cumulative Distribution Function (ECDF)\", fontsize=20, y=0.99)\n",
    "for time in natsorted(coverage_df[\"time\"].unique()):\n",
    "    filtered_by_time_df = coverage_df[coverage_df[\"time\"] == time]\n",
    "    filtered_by_time_df = filtered_by_time_df.drop(columns=\"time\")\n",
    "    filtered_by_time_df = filtered_by_time_df.groupby([\"util\", \"key\"]).mean()\n",
    "    filtered_by_time_df = filtered_by_time_df.reset_index()\n",
    "    for key_i, key in enumerate(np.sort(keys)):\n",
    "        filtered_by_key_df = filtered_by_time_df[filtered_by_time_df['key'] == key]\n",
    "        axes[key_i].set_title(key)\n",
    "        sns.ecdfplot(y=\"value\", data=filtered_by_key_df, ax=axes[key_i], label=time)\n",
    "        axes[key_i].legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"plots/by-time.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gains by time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13988/361646667.py:15: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df_keys = df_keys.groupby([\"time\"]).mean()\n",
      "/tmp/ipykernel_13988/361646667.py:15: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df_keys = df_keys.groupby([\"time\"]).mean()\n",
      "/tmp/ipykernel_13988/361646667.py:15: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df_keys = df_keys.groupby([\"time\"]).mean()\n",
      "/tmp/ipykernel_13988/361646667.py:15: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df_keys = df_keys.groupby([\"time\"]).mean()\n"
     ]
    }
   ],
   "source": [
    "df = combined_df.drop(columns=[\"DataFrame\"])\n",
    "df = df.groupby([\"key\", \"time\", \"util\"]).mean()\n",
    "df = df.reset_index()\n",
    "keys = np.sort(df[\"key\"].unique())\n",
    "fig, axes = plt.subplots(nrows=len(keys), ncols=1, figsize=(5, 3*len(keys)), dpi=300)\n",
    "for i, key in enumerate(keys):\n",
    "    df_keys = df[df[\"key\"] == key]\n",
    "    df_keys = df_keys.drop(columns=\"key\")\n",
    "    order = natsorted(df_keys[\"time\"].unique())\n",
    "    df_keys['time'] = pd.Categorical(df_keys['time'], categories=order, ordered=True)\n",
    "    df_keys = df_keys.sort_values(['util', 'time'])\n",
    "    df_keys['difference'] = df_keys.groupby('util')['value'].diff()\n",
    "    df_keys = df_keys.reset_index()\n",
    "    df_keys = df_keys.drop(columns=[\"util\", \"value\"])\n",
    "    df_keys = df_keys.groupby([\"time\"]).mean()\n",
    "    df_keys = df_keys.reset_index()\n",
    "    df_keys['time'] = df_keys['time'].shift(1).astype(str) + ' - ' + df_keys['time'].astype(str)\n",
    "    df_keys = df_keys.dropna()\n",
    "    sns.barplot(data=df_keys, x=\"time\", y=\"difference\", ax=axes[i])\n",
    "    axes[i].set_ylabel(f\"average {key} gained\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"plots/gains_by_time.png\")\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots by util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with gcov_cov\n",
      "Done with klee_BCov\n",
      "Done with klee_ICov\n",
      "Done with num_errors\n"
     ]
    }
   ],
   "source": [
    "keys = np.sort(combined_df[\"key\"].unique())\n",
    "for key in keys:\n",
    "    filtered_by_key_df = combined_df[combined_df[\"key\"] == key]\n",
    "    utils = np.sort(filtered_by_key_df[\"util\"].unique())\n",
    "    fig, axes = plt.subplots(\n",
    "            nrows=int(np.ceil(len(utils)/5)),\n",
    "            ncols=5,\n",
    "            figsize=(25, len(utils)),\n",
    "            dpi=300\n",
    "        )\n",
    "    for i_util, util in enumerate(utils):\n",
    "        filtered_by_util_df = filtered_by_key_df[filtered_by_key_df['util'] == util]\n",
    "        ax = axes[i_util//5, i_util%5]\n",
    "        ax.set_title(f\"{util}\")\n",
    "        ax.set_ylabel(key)\n",
    "        order = natsorted(filtered_by_util_df[\"time\"].unique())\n",
    "        sns.boxplot(x=\"time\", y=\"value\", data=filtered_by_util_df, ax=ax, order=order)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots/by-util/{key}.png\")\n",
    "    plt.close()\n",
    "    print(f\"Done with {key}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
