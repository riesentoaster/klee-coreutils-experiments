{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Any, Dict\n",
    "import re\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "from natsort import natsorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global information about each suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = {\n",
    "    run: {\"version\": version.name}\n",
    "    for version in Path(\"./out\").iterdir()\n",
    "    for run in version.iterdir()\n",
    "}\n",
    "\n",
    "\n",
    "def add_entry_to_run(\n",
    "    new_key: str, f: Callable[[Path, Dict[str, Any]], Any]\n",
    ") -> Dict[Path, Dict[str, Any]]:\n",
    "    global runs\n",
    "    for key, value in runs.items():\n",
    "        value.update({new_key: f(key, value)})\n",
    "\n",
    "\n",
    "add_entry_to_run(\"name\", lambda p, d: p.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time(p:Path, d):\n",
    "    file_path = p.rglob(\"klee/info\").__next__()\n",
    "    if file_path.exists():\n",
    "        with open(file_path, \"r\") as file:\n",
    "            res = re.search(r\"--max-time=(\\w*)\", file.read())\n",
    "            if res:\n",
    "                return res.group(1)\n",
    "\n",
    "    print(f\"Error for {p}\")\n",
    "    return None\n",
    "\n",
    "add_entry_to_run(\"time\", get_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per util information\n",
    "\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_entry_to_run(\"df\", lambda p, d: pd.DataFrame(columns=[e.name for e in p.iterdir() if e.is_dir()]))\n",
    "\n",
    "def add_entry_for_utils(key: str, f: Callable[[Path], Any]) -> None:\n",
    "    \"\"\"\n",
    "    Add entry for all utils\n",
    "\n",
    "    Paramenters:\n",
    "    key (str): key to add the new value at in the dataframe\n",
    "    f (Callable[[Path], Any]): function taking the path to the subfolder for the util and returning the appropriate value\n",
    "    \"\"\"\n",
    "\n",
    "    def adder(p: Path, d):\n",
    "        df = d[\"df\"]\n",
    "        res = {}\n",
    "        for util in df.columns:\n",
    "            path = p / util\n",
    "            if not path.exists():\n",
    "                raise Exception(f\"Path \\\"{util}\\\" does not exist\")\n",
    "            res[util] = f(path)\n",
    "        df.loc[key] = res\n",
    "        return df\n",
    "    add_entry_to_run(\"df\", adder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of errors according to KLEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for out/coreutils-8.25/1h-3/hostname\n",
      "Error for out/coreutils-8.25/1h-3/setuidgid\n",
      "Error for out/coreutils-8.25/1h-2/hostname\n",
      "Error for out/coreutils-8.25/1h-2/setuidgid\n",
      "Error for out/coreutils-8.25/1h/hostname\n",
      "Error for out/coreutils-8.25/1h/setuidgid\n",
      "Error for out/coreutils-9.4/1h-3/hostname\n",
      "Error for out/coreutils-9.4/1h-3/setuidgid\n",
      "Error for out/coreutils-9.4/1h-2/hostname\n",
      "Error for out/coreutils-9.4/1h-2/setuidgid\n",
      "Error for out/coreutils-9.4/1h/hostname\n",
      "Error for out/coreutils-9.4/1h/setuidgid\n",
      "Error for out/coreutils-8.25/1h-3/hostname\n",
      "Error for out/coreutils-8.25/1h-3/setuidgid\n",
      "Error for out/coreutils-8.25/1h-2/hostname\n",
      "Error for out/coreutils-8.25/1h-2/setuidgid\n",
      "Error for out/coreutils-8.25/1h/hostname\n",
      "Error for out/coreutils-8.25/1h/setuidgid\n",
      "Error for out/coreutils-9.4/1h-3/hostname\n",
      "Error for out/coreutils-9.4/1h-3/setuidgid\n",
      "Error for out/coreutils-9.4/1h-2/hostname\n",
      "Error for out/coreutils-9.4/1h-2/setuidgid\n",
      "Error for out/coreutils-9.4/1h/hostname\n",
      "Error for out/coreutils-9.4/1h/setuidgid\n",
      "Error for out/coreutils-8.25/1h-3/hostname\n",
      "Error for out/coreutils-8.25/1h-3/setuidgid\n",
      "Error for out/coreutils-8.25/1h-2/hostname\n",
      "Error for out/coreutils-8.25/1h-2/setuidgid\n",
      "Error for out/coreutils-8.25/1h/hostname\n",
      "Error for out/coreutils-8.25/1h/setuidgid\n",
      "Error for out/coreutils-9.4/1h-3/hostname\n",
      "Error for out/coreutils-9.4/1h-3/setuidgid\n",
      "Error for out/coreutils-9.4/1h-2/hostname\n",
      "Error for out/coreutils-9.4/1h-2/setuidgid\n",
      "Error for out/coreutils-9.4/1h/hostname\n",
      "Error for out/coreutils-9.4/1h/setuidgid\n",
      "Error for out/coreutils-8.25/1h-3/hostname\n",
      "Error for out/coreutils-8.25/1h-3/setuidgid\n",
      "Error for out/coreutils-8.25/1h-2/hostname\n",
      "Error for out/coreutils-8.25/1h-2/setuidgid\n",
      "Error for out/coreutils-8.25/1h/hostname\n",
      "Error for out/coreutils-8.25/1h/setuidgid\n",
      "Error for out/coreutils-9.4/1h-3/hostname\n",
      "Error for out/coreutils-9.4/1h-3/setuidgid\n",
      "Error for out/coreutils-9.4/1h-2/hostname\n",
      "Error for out/coreutils-9.4/1h-2/setuidgid\n",
      "Error for out/coreutils-9.4/1h/hostname\n",
      "Error for out/coreutils-9.4/1h/setuidgid\n",
      "Error for out/coreutils-8.25/1h-3/hostname\n",
      "Error for out/coreutils-8.25/1h-3/setuidgid\n",
      "Error for out/coreutils-8.25/1h-2/hostname\n",
      "Error for out/coreutils-8.25/1h-2/setuidgid\n",
      "Error for out/coreutils-8.25/1h/hostname\n",
      "Error for out/coreutils-8.25/1h/setuidgid\n",
      "Error for out/coreutils-9.4/1h-3/hostname\n",
      "Error for out/coreutils-9.4/1h-3/setuidgid\n",
      "Error for out/coreutils-9.4/1h-2/hostname\n",
      "Error for out/coreutils-9.4/1h-2/setuidgid\n",
      "Error for out/coreutils-9.4/1h/hostname\n",
      "Error for out/coreutils-9.4/1h/setuidgid\n",
      "Error for out/coreutils-8.25/1h-3/hostname\n",
      "Error for out/coreutils-8.25/1h-3/setuidgid\n",
      "Error for out/coreutils-8.25/1h-2/hostname\n",
      "Error for out/coreutils-8.25/1h-2/setuidgid\n",
      "Error for out/coreutils-8.25/1h/hostname\n",
      "Error for out/coreutils-8.25/1h/setuidgid\n",
      "Error for out/coreutils-9.4/1h-3/hostname\n",
      "Error for out/coreutils-9.4/1h-3/setuidgid\n",
      "Error for out/coreutils-9.4/1h-2/hostname\n",
      "Error for out/coreutils-9.4/1h-2/setuidgid\n",
      "Error for out/coreutils-9.4/1h/hostname\n",
      "Error for out/coreutils-9.4/1h/setuidgid\n"
     ]
    }
   ],
   "source": [
    "def read_num_errors(error_type:str) -> Callable[[Path], str]:\n",
    "    def f(util_path: Path) -> str:\n",
    "        file_path = util_path / \"klee\"\n",
    "        if file_path.exists():\n",
    "            return str(len(list(file_path.glob(f\"*{error_type}.err\"))))\n",
    "        else:\n",
    "            print(f\"Error for {util_path}\")\n",
    "            return None\n",
    "    return f\n",
    "error_types = [file.name for run in runs.keys() for file in list(run.glob(\"**/*.err\"))]\n",
    "error_types = [e.split(\".\")[-2] for e in error_types]\n",
    "error_types = list(set(error_types))\n",
    "for error_type in error_types:\n",
    "    add_entry_for_utils(f\"num_errors ({error_type})\", read_num_errors(error_type))\n",
    "add_entry_for_utils(f\"num_errors (total)\", read_num_errors(\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coverage according to KLEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for ICov(%) — out/coreutils-8.25/1h-3/hostname\n",
      "Error for ICov(%) — out/coreutils-8.25/1h-3/setuidgid\n",
      "Error for ICov(%) — out/coreutils-8.25/1h-2/hostname\n",
      "Error for ICov(%) — out/coreutils-8.25/1h-2/setuidgid\n",
      "Error for ICov(%) — out/coreutils-8.25/1h/hostname\n",
      "Error for ICov(%) — out/coreutils-8.25/1h/setuidgid\n",
      "Error for ICov(%) — out/coreutils-9.4/1h-3/hostname\n",
      "Error for ICov(%) — out/coreutils-9.4/1h-3/setuidgid\n",
      "Error for ICov(%) — out/coreutils-9.4/1h-2/hostname\n",
      "Error for ICov(%) — out/coreutils-9.4/1h-2/setuidgid\n",
      "Error for ICov(%) — out/coreutils-9.4/1h/hostname\n",
      "Error for ICov(%) — out/coreutils-9.4/1h/setuidgid\n",
      "Error for BCov(%) — out/coreutils-8.25/1h-3/hostname\n",
      "Error for BCov(%) — out/coreutils-8.25/1h-3/setuidgid\n",
      "Error for BCov(%) — out/coreutils-8.25/1h-2/hostname\n",
      "Error for BCov(%) — out/coreutils-8.25/1h-2/setuidgid\n",
      "Error for BCov(%) — out/coreutils-8.25/1h/hostname\n",
      "Error for BCov(%) — out/coreutils-8.25/1h/setuidgid\n",
      "Error for BCov(%) — out/coreutils-9.4/1h-3/hostname\n",
      "Error for BCov(%) — out/coreutils-9.4/1h-3/setuidgid\n",
      "Error for BCov(%) — out/coreutils-9.4/1h-2/hostname\n",
      "Error for BCov(%) — out/coreutils-9.4/1h-2/setuidgid\n",
      "Error for BCov(%) — out/coreutils-9.4/1h/hostname\n",
      "Error for BCov(%) — out/coreutils-9.4/1h/setuidgid\n"
     ]
    }
   ],
   "source": [
    "def read_klee_csv(csv_name: str) -> Callable[[Path], str]:\n",
    "    def f(util_path: Path) -> str:\n",
    "        file_path = util_path / \"klee-stats.csv\"\n",
    "        if file_path.exists() and file_path.stat().st_size > 0:\n",
    "            df = pd.read_csv(file_path)\n",
    "            return str(df[csv_name][0])\n",
    "        else:\n",
    "            print(f\"Error for {csv_name} — {util_path}\")\n",
    "            return None\n",
    "    return f\n",
    "\n",
    "add_entry_for_utils(\"klee_ICov\", read_klee_csv(\"ICov(%)\"))\n",
    "add_entry_for_utils(\"klee_BCov\", read_klee_csv(\"BCov(%)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coverage according to `gcov`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for out/coreutils-8.25/1h-3/hostname\n",
      "Error for out/coreutils-8.25/1h-3/[\n",
      "Error for out/coreutils-8.25/1h-3/base64\n",
      "Error for out/coreutils-8.25/1h-3/setuidgid\n",
      "Error for out/coreutils-8.25/1h-3/md5sum\n",
      "Error for out/coreutils-8.25/1h-3/ginstall\n",
      "Error for out/coreutils-8.25/1h-2/hostname\n",
      "Error for out/coreutils-8.25/1h-2/[\n",
      "Error for out/coreutils-8.25/1h-2/base64\n",
      "Error for out/coreutils-8.25/1h-2/setuidgid\n",
      "Error for out/coreutils-8.25/1h-2/md5sum\n",
      "Error for out/coreutils-8.25/1h-2/ginstall\n",
      "Error for out/coreutils-8.25/1h/hostname\n",
      "Error for out/coreutils-8.25/1h/[\n",
      "Error for out/coreutils-8.25/1h/base64\n",
      "Error for out/coreutils-8.25/1h/setuidgid\n",
      "Error for out/coreutils-8.25/1h/md5sum\n",
      "Error for out/coreutils-8.25/1h/ginstall\n",
      "Error for out/coreutils-6.10/24h-3/md5sum\n",
      "Error for out/coreutils-6.10/24h-3/ginstall\n",
      "Error for out/coreutils-6.10/6h-3/uniq\n",
      "Error for out/coreutils-6.10/6h-3/who\n",
      "Error for out/coreutils-6.10/6h-3/md5sum\n",
      "Error for out/coreutils-6.10/6h-3/tsort\n",
      "Error for out/coreutils-6.10/6h-3/ginstall\n",
      "Error for out/coreutils-6.10/24h/md5sum\n",
      "Error for out/coreutils-6.10/24h/ginstall\n",
      "Error for out/coreutils-6.10/6h-2/md5sum\n",
      "Error for out/coreutils-6.10/6h-2/ginstall\n",
      "Error for out/coreutils-6.10/1h-3/md5sum\n",
      "Error for out/coreutils-6.10/1h-3/ginstall\n",
      "Error for out/coreutils-6.10/6h/md5sum\n",
      "Error for out/coreutils-6.10/6h/ginstall\n",
      "Error for out/coreutils-6.10/1h-2/[\n",
      "Error for out/coreutils-6.10/1h-2/md5sum\n",
      "Error for out/coreutils-6.10/1h-2/ginstall\n",
      "Error for out/coreutils-6.10/1h-4/md5sum\n",
      "Error for out/coreutils-6.10/1h-4/ginstall\n",
      "Error for out/coreutils-6.10/24h-2/md5sum\n",
      "Error for out/coreutils-6.10/24h-2/ginstall\n",
      "Error for out/coreutils-6.10/10min/md5sum\n",
      "Error for out/coreutils-6.10/10min/ginstall\n",
      "Error for out/coreutils-6.10/10min-3/md5sum\n",
      "Error for out/coreutils-6.10/10min-3/ginstall\n",
      "Error for out/coreutils-6.10/1h/[\n",
      "Error for out/coreutils-6.10/1h/md5sum\n",
      "Error for out/coreutils-6.10/1h/ginstall\n",
      "Error for out/coreutils-6.10/10min-2/md5sum\n",
      "Error for out/coreutils-6.10/10min-2/ginstall\n",
      "Error for out/coreutils-9.4/1h-3/hostname\n",
      "Error for out/coreutils-9.4/1h-3/[\n",
      "Error for out/coreutils-9.4/1h-3/sum\n",
      "Error for out/coreutils-9.4/1h-3/base64\n",
      "Error for out/coreutils-9.4/1h-3/setuidgid\n",
      "Error for out/coreutils-9.4/1h-3/cksum\n",
      "Error for out/coreutils-9.4/1h-3/wc\n",
      "Error for out/coreutils-9.4/1h-3/md5sum\n",
      "Error for out/coreutils-9.4/1h-3/ginstall\n",
      "Error for out/coreutils-9.4/1h-2/hostname\n",
      "Error for out/coreutils-9.4/1h-2/[\n",
      "Error for out/coreutils-9.4/1h-2/sum\n",
      "Error for out/coreutils-9.4/1h-2/base64\n",
      "Error for out/coreutils-9.4/1h-2/setuidgid\n",
      "Error for out/coreutils-9.4/1h-2/cksum\n",
      "Error for out/coreutils-9.4/1h-2/wc\n",
      "Error for out/coreutils-9.4/1h-2/md5sum\n",
      "Error for out/coreutils-9.4/1h-2/ginstall\n",
      "Error for out/coreutils-9.4/1h/hostname\n",
      "Error for out/coreutils-9.4/1h/[\n",
      "Error for out/coreutils-9.4/1h/sum\n",
      "Error for out/coreutils-9.4/1h/base64\n",
      "Error for out/coreutils-9.4/1h/setuidgid\n",
      "Error for out/coreutils-9.4/1h/cksum\n",
      "Error for out/coreutils-9.4/1h/wc\n",
      "Error for out/coreutils-9.4/1h/md5sum\n",
      "Error for out/coreutils-9.4/1h/ginstall\n"
     ]
    }
   ],
   "source": [
    "def read_gcov_cov(util_path: Path) -> str:\n",
    "    file_path = util_path / \"cov.txt\"\n",
    "    if file_path.exists():\n",
    "        with open(file_path, \"r\") as file:\n",
    "            res = re.search(r\"File '(\\.\\./)?\\.\\./src/(\\w+)\\.c'\\nLines executed:(\\d?\\d\\d.\\d\\d)% of \\d+\", file.read())\n",
    "            if res:\n",
    "                return res.group(3)\n",
    "    print(f\"Error for {util_path}\")\n",
    "    return None\n",
    "\n",
    "add_entry_for_utils(\"gcov_cov\", read_gcov_cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots\n",
    "### Massaging `df`s together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       key       util  value      run     time         version\n",
      "4710             klee_ICov         ln  43.24     6h-2   360min  coreutils-6.10\n",
      "1589    num_errors (model)   unexpand   1.00       1h    60min  coreutils-8.25\n",
      "6461             klee_ICov    pathchk  43.24       6h   360min  coreutils-6.10\n",
      "6018     num_errors (exec)      nohup   0.00     1h-3    60min  coreutils-6.10\n",
      "4126    num_errors (total)        fmt   2.00      24h  1440min  coreutils-6.10\n",
      "6387    num_errors (model)        env   0.00       6h   360min  coreutils-6.10\n",
      "0         num_errors (ptr)         ln   0.00     1h-3    60min  coreutils-8.25\n",
      "10401            klee_ICov       nice  39.90  10min-3    10min  coreutils-6.10\n",
      "1436    num_errors (abort)      pinky   0.00     1h-2    60min  coreutils-8.25\n",
      "8186              gcov_cov        tac  71.23     1h-4    60min  coreutils-6.10\n",
      "4916    num_errors (total)        fmt   0.00     6h-2   360min  coreutils-6.10\n",
      "5877    num_errors (total)     expand   0.00     1h-3    60min  coreutils-6.10\n",
      "12206            klee_BCov       uniq  32.23  10min-2    10min  coreutils-6.10\n",
      "714              klee_BCov  dircolors  30.00     1h-3    60min  coreutils-8.25\n",
      "3777             klee_ICov      split  45.18     6h-3   360min  coreutils-6.10\n",
      "3703     num_errors (exec)   printenv   0.00     6h-3   360min  coreutils-6.10\n",
      "10188     num_errors (ptr)         cp   0.00    10min    10min  coreutils-6.10\n",
      "7685   num_errors (solver)     csplit   0.00     1h-2    60min  coreutils-6.10\n",
      "11193     num_errors (ptr)       nice   0.00       1h    60min  coreutils-6.10\n",
      "1548              gcov_cov         tr  66.23     1h-2    60min  coreutils-8.25\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for k, v in runs.items():\n",
    "    df = v[\"df\"]\n",
    "    df = df.reset_index(names=\"key\")\n",
    "    df = df.melt(id_vars=\"key\", var_name=\"util\")\n",
    "    df[\"run\"] = k.name\n",
    "    df[\"time\"] = v[\"time\"]\n",
    "    df[\"version\"] = v[\"version\"]\n",
    "    dfs.append(df)\n",
    "\n",
    "combined_df = pd.concat(dfs)\n",
    "combined_df['value'] = combined_df['value'].astype(np.float64)\n",
    "combined_df = combined_df.dropna(subset=['value'])\n",
    "combined_df = combined_df.reset_index(drop=True)\n",
    "print(combined_df.sample(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots by coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage_df = combined_df\n",
    "versions = natsorted(coverage_df[\"version\"].unique())\n",
    "keys = natsorted(coverage_df[\"key\"].unique())\n",
    "time_categories = natsorted(coverage_df[\"time\"].unique())\n",
    "\n",
    "color_map = dict(zip(time_categories, sns.color_palette(n_colors=len(time_categories))))\n",
    "\n",
    "\n",
    "def paint_util(args):\n",
    "    key, key_df = args\n",
    "    fig, axes = plt.subplots(\n",
    "        ncols=1,\n",
    "        nrows=len(versions),\n",
    "        figsize=(10, 5 * len(versions)),\n",
    "        dpi=300,\n",
    "    )\n",
    "    fig.suptitle(\n",
    "        f\"Empirical Cumulative Distribution Function (ECDF) for {key}\",\n",
    "        fontsize=20,\n",
    "        y=0.99,\n",
    "    )\n",
    "    for version_i, version in enumerate(versions):\n",
    "        version_df = key_df[key_df[\"version\"] == version].drop(columns=\"version\")\n",
    "        ax = axes[version_i]\n",
    "        ax.set_title(version)\n",
    "        for time in natsorted(version_df[\"time\"].unique()):\n",
    "            time_df = version_df[version_df[\"time\"] == time].drop(columns=\"time\")\n",
    "            for run_i, run in enumerate(time_df[\"run\"].unique()):\n",
    "                run_df = time_df[time_df[\"run\"] == run].drop(columns=\"run\")\n",
    "                sns.ecdfplot(\n",
    "                    y=\"value\",\n",
    "                    data=run_df,\n",
    "                    ax=ax,\n",
    "                    color=color_map[time],\n",
    "                    label=time if run_i == 0 else \"_nolegend_\",\n",
    "                    stat=\"count\",\n",
    "                )\n",
    "        ax.legend(title=\"Time\")\n",
    "    plt.tight_layout()\n",
    "    Path(f\"plots/{key}\").mkdir(exist_ok=True, parents=True)\n",
    "    plt.savefig(f\"plots/{key}/ecdf.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "with multiprocessing.Pool() as pool:\n",
    "    pool.map(\n",
    "        paint_util,\n",
    "        [\n",
    "            (key, combined_df[combined_df[\"key\"] == key].drop(columns=\"key\"))\n",
    "            for key in natsorted(combined_df[\"key\"].unique())\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gains by time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = combined_df[combined_df[\"version\"] == \"coreutils-6.10\"].drop(\n",
    "    columns=[\"run\", \"version\"]\n",
    ")\n",
    "df = df.groupby([\"key\", \"time\", \"util\"], as_index=False).mean()\n",
    "keys = natsorted(df[\"key\"].unique())\n",
    "fig, axes = plt.subplots(nrows=len(keys), ncols=1, figsize=(5, 3 * len(keys)), dpi=300)\n",
    "for i, key in enumerate(keys):\n",
    "    df_keys = df[df[\"key\"] == key]\n",
    "    df_keys = df_keys.drop(columns=\"key\")\n",
    "    order = natsorted(df_keys[\"time\"].unique())\n",
    "    df_keys[\"time\"] = pd.Categorical(df_keys[\"time\"], categories=order, ordered=True)\n",
    "    df_keys = df_keys.sort_values([\"util\", \"time\"])\n",
    "    df_keys[\"difference\"] = df_keys.groupby(\"util\", as_index=False)[\"value\"].diff()\n",
    "    df_keys = df_keys.drop(columns=[\"util\", \"value\"])\n",
    "    df_keys = df_keys.groupby([\"time\"], as_index=False, observed=True).mean()\n",
    "    df_keys[\"time\"] = (\n",
    "        df_keys[\"time\"].shift(1).astype(str) + \" - \" + df_keys[\"time\"].astype(str)\n",
    "    )\n",
    "    df_keys = df_keys.dropna()\n",
    "    sns.barplot(data=df_keys, x=\"time\", y=\"difference\", ax=axes[i])\n",
    "    axes[i].set_ylabel(f\"average {key} gained\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"plots/gains_by_time.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots by util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_stripplot = {\n",
    "    \"alpha\": 0.3,\n",
    "    \"size\": 2,\n",
    "    \"y\": \"value_normalized\",\n",
    "    \"jitter\": 0.3,\n",
    "}\n",
    "args_pointplot = {\n",
    "    \"y\": \"value_normalized\",\n",
    "    \"color\": \"red\",\n",
    "    \"markers\": \"_\",\n",
    "    \"markersize\": 100,\n",
    "    \"markeredgewidth\": 1,\n",
    "    \"linestyles\": \"none\",\n",
    "    \"zorder\": 10,\n",
    "}\n",
    "\n",
    "handles = [\n",
    "    plt.Line2D(\n",
    "        [], [], linestyle=\"none\", marker=\"o\", markersize=2, color=\"blue\", label=\"values\"\n",
    "    ),\n",
    "    plt.Line2D([], [], color=\"red\", label=\"average\"),\n",
    "]\n",
    "\n",
    "\n",
    "def paint_util(args):\n",
    "    key, df = args\n",
    "    df_norm = df[(df[\"time\"] == \"60min\") & (df[\"version\"] == \"coreutils-6.10\")]\n",
    "    df_norm = df_norm.drop(columns=[\"time\", \"version\", \"run\"])\n",
    "    df_norm = df_norm.groupby(by=\"util\", as_index=False, observed=True)[\"value\"].mean()\n",
    "    df_norm = df_norm.rename(columns={\"value\": \"value_avg\"})\n",
    "    df = df.merge(df_norm, on=\"util\", how=\"left\")\n",
    "    df[\"value_normalized\"] = df[\"value\"] - df[\"value_avg\"]\n",
    "    df_version = df[df[\"version\"] == \"coreutils-6.10\"]\n",
    "    df_time = df[df[\"time\"] == \"60min\"]\n",
    "    times = natsorted(df[\"time\"].unique())\n",
    "    versions = natsorted(df[\"version\"].unique())\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(8, 10), dpi=300)\n",
    "    fig.suptitle(f\"Normalized Changes of {key}\")\n",
    "\n",
    "    def get_avg(df_to_average: pd.DataFrame, key: str) -> pd.DataFrame:\n",
    "        return (\n",
    "            df_to_average[[key, \"value_normalized\"]]\n",
    "            .groupby(key, as_index=False, observed=True)[\"value_normalized\"]\n",
    "            .mean()\n",
    "        )\n",
    "\n",
    "    sns.stripplot(data=df_version, ax=ax[0], x=\"time\", order=times, **args_stripplot)\n",
    "    sns.pointplot(\n",
    "        data=get_avg(df_version, \"time\"),\n",
    "        ax=ax[0],\n",
    "        x=\"time\",\n",
    "        order=times,\n",
    "        **args_pointplot,\n",
    "    )\n",
    "\n",
    "    ax[0].set_title(\"changes based on time\")\n",
    "    ax[0].set_ylabel(\"changes compared\\nto the average\\nof all 60min runs\")\n",
    "    ax[0].legend(handles=handles)\n",
    "\n",
    "    sns.stripplot(data=df_time, ax=ax[1], x=\"version\", order=versions, **args_stripplot)\n",
    "    sns.pointplot(\n",
    "        data=get_avg(df_time, \"version\"),\n",
    "        ax=ax[1],\n",
    "        x=\"version\",\n",
    "        order=versions,\n",
    "        **args_pointplot,\n",
    "    )\n",
    "    ax[1].set_title(\"changes based on version\")\n",
    "    ax[1].set_ylabel(\"changes compared\\nto the average\\nof all 6.10 runs\")\n",
    "    ax[1].legend(handles=handles)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    Path(f\"plots/{key}\").mkdir(exist_ok=True, parents=True)\n",
    "    fig.savefig(f\"plots/{key}/changes.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "with multiprocessing.Pool() as pool:\n",
    "    pool.map(\n",
    "        paint_util,\n",
    "        [\n",
    "            (key, combined_df[combined_df[\"key\"] == key].drop(columns=\"key\"))\n",
    "            for key in natsorted(combined_df[\"key\"].unique())\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with gcov_cov\n",
      "Done with klee_BCov\n",
      "Done with klee_ICov\n",
      "Done with num_errors (abort)\n",
      "Done with num_errors (exec)\n",
      "Done with num_errors (model)\n",
      "Done with num_errors (ptr)\n",
      "Done with num_errors (solver)\n",
      "Done with num_errors (total)\n"
     ]
    }
   ],
   "source": [
    "def paint_util(args):\n",
    "    key, util, key_df = args\n",
    "    util_df = key_df[key_df[\"util\"] == util].drop(columns=\"util\")\n",
    "    util_df = util_df.sort_values(by=\"version\")\n",
    "    times = natsorted(util_df['time'].unique())\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 6), dpi=300)\n",
    "    sns.stripplot(data=util_df, ax=ax, x='time', y=\"value\", hue=\"version\", order=times)\n",
    "    ax.set_title(f\"{util}\")\n",
    "    ax.set_ylabel(key)\n",
    "    fig.tight_layout()\n",
    "    Path(f\"plots/{key}/by-util\").mkdir(exist_ok=True, parents=True)\n",
    "    fig.savefig(f\"plots/{key}/by-util/{util}.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "for key in natsorted(combined_df[\"key\"].unique()):\n",
    "    key_df = combined_df[combined_df[\"key\"] == key].drop(columns=\"key\")\n",
    "    \n",
    "    utils = natsorted(key_df[\"util\"].unique())\n",
    "\n",
    "    with multiprocessing.Pool() as pool:\n",
    "        pool.map(paint_util, [(key, util, key_df) for util in utils])\n",
    "    \n",
    "    print(f\"Done with {key}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
