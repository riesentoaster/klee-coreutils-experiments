{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Any, Dict\n",
    "import re\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "from natsort import natsorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global information about each suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = {\n",
    "    run: {\"version\": version.name}\n",
    "    for version in Path(\"./out\").iterdir()\n",
    "    for run in version.iterdir()\n",
    "}\n",
    "\n",
    "\n",
    "def add_entry_to_run(\n",
    "    new_key: str, f: Callable[[Path, Dict[str, Any]], Any]\n",
    ") -> Dict[Path, Dict[str, Any]]:\n",
    "    global runs\n",
    "    for key, value in runs.items():\n",
    "        value.update({new_key: f(key, value)})\n",
    "\n",
    "\n",
    "add_entry_to_run(\"name\", lambda p, d: p.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time(p:Path, d):\n",
    "    file_path = p.rglob(\"klee/info\").__next__()\n",
    "    if file_path.exists():\n",
    "        with open(file_path, \"r\") as file:\n",
    "            res = re.search(r\"--max-time=(\\w*)\", file.read())\n",
    "            if res:\n",
    "                return res.group(1)\n",
    "    else:\n",
    "        print(f\"Error for {p}\")\n",
    "        return None\n",
    "\n",
    "add_entry_to_run(\"time\", get_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per util information\n",
    "\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_entry_to_run(\"df\", lambda p, d: pd.DataFrame(columns=[e.name for e in p.iterdir() if e.is_dir()]))\n",
    "\n",
    "def add_entry_for_utils(key: str, f: Callable[[Path], Any]) -> None:\n",
    "    \"\"\"\n",
    "    Add entry for all utils\n",
    "\n",
    "    Paramenters:\n",
    "    key (str): key to add the new value at in the dataframe\n",
    "    f (Callable[[Path], Any]): function taking the path to the subfolder for the util and returning the appropriate value\n",
    "    \"\"\"\n",
    "\n",
    "    def adder(p: Path, d):\n",
    "        df = d[\"df\"]\n",
    "        res = {}\n",
    "        for util in df.columns:\n",
    "            path = p / util\n",
    "            if not path.exists():\n",
    "                raise Exception(f\"Path \\\"{util}\\\" does not exist\")\n",
    "            res[util] = f(path)\n",
    "        df.loc[key] = res\n",
    "        return df\n",
    "    add_entry_to_run(\"df\", adder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of errors according to KLEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for out/coreutils-8.25/1h-3/hostname\n",
      "Error for out/coreutils-8.25/1h-3/setuidgid\n",
      "Error for out/coreutils-8.25/1h-2/hostname\n",
      "Error for out/coreutils-8.25/1h-2/setuidgid\n",
      "Error for out/coreutils-8.25/1h/hostname\n",
      "Error for out/coreutils-8.25/1h/setuidgid\n",
      "Error for out/coreutils-9.4/1h-3/hostname\n",
      "Error for out/coreutils-9.4/1h-3/setuidgid\n",
      "Error for out/coreutils-9.4/1h-2/hostname\n",
      "Error for out/coreutils-9.4/1h-2/setuidgid\n",
      "Error for out/coreutils-9.4/1h/hostname\n",
      "Error for out/coreutils-9.4/1h/setuidgid\n",
      "Error for out/coreutils-8.25/1h-3/hostname\n",
      "Error for out/coreutils-8.25/1h-3/setuidgid\n",
      "Error for out/coreutils-8.25/1h-2/hostname\n",
      "Error for out/coreutils-8.25/1h-2/setuidgid\n",
      "Error for out/coreutils-8.25/1h/hostname\n",
      "Error for out/coreutils-8.25/1h/setuidgid\n",
      "Error for out/coreutils-9.4/1h-3/hostname\n",
      "Error for out/coreutils-9.4/1h-3/setuidgid\n",
      "Error for out/coreutils-9.4/1h-2/hostname\n",
      "Error for out/coreutils-9.4/1h-2/setuidgid\n",
      "Error for out/coreutils-9.4/1h/hostname\n",
      "Error for out/coreutils-9.4/1h/setuidgid\n",
      "Error for out/coreutils-8.25/1h-3/hostname\n",
      "Error for out/coreutils-8.25/1h-3/setuidgid\n",
      "Error for out/coreutils-8.25/1h-2/hostname\n",
      "Error for out/coreutils-8.25/1h-2/setuidgid\n",
      "Error for out/coreutils-8.25/1h/hostname\n",
      "Error for out/coreutils-8.25/1h/setuidgid\n",
      "Error for out/coreutils-9.4/1h-3/hostname\n",
      "Error for out/coreutils-9.4/1h-3/setuidgid\n",
      "Error for out/coreutils-9.4/1h-2/hostname\n",
      "Error for out/coreutils-9.4/1h-2/setuidgid\n",
      "Error for out/coreutils-9.4/1h/hostname\n",
      "Error for out/coreutils-9.4/1h/setuidgid\n",
      "Error for out/coreutils-8.25/1h-3/hostname\n",
      "Error for out/coreutils-8.25/1h-3/setuidgid\n",
      "Error for out/coreutils-8.25/1h-2/hostname\n",
      "Error for out/coreutils-8.25/1h-2/setuidgid\n",
      "Error for out/coreutils-8.25/1h/hostname\n",
      "Error for out/coreutils-8.25/1h/setuidgid\n",
      "Error for out/coreutils-9.4/1h-3/hostname\n",
      "Error for out/coreutils-9.4/1h-3/setuidgid\n",
      "Error for out/coreutils-9.4/1h-2/hostname\n",
      "Error for out/coreutils-9.4/1h-2/setuidgid\n",
      "Error for out/coreutils-9.4/1h/hostname\n",
      "Error for out/coreutils-9.4/1h/setuidgid\n",
      "Error for out/coreutils-8.25/1h-3/hostname\n",
      "Error for out/coreutils-8.25/1h-3/setuidgid\n",
      "Error for out/coreutils-8.25/1h-2/hostname\n",
      "Error for out/coreutils-8.25/1h-2/setuidgid\n",
      "Error for out/coreutils-8.25/1h/hostname\n",
      "Error for out/coreutils-8.25/1h/setuidgid\n",
      "Error for out/coreutils-9.4/1h-3/hostname\n",
      "Error for out/coreutils-9.4/1h-3/setuidgid\n",
      "Error for out/coreutils-9.4/1h-2/hostname\n",
      "Error for out/coreutils-9.4/1h-2/setuidgid\n",
      "Error for out/coreutils-9.4/1h/hostname\n",
      "Error for out/coreutils-9.4/1h/setuidgid\n",
      "Error for out/coreutils-8.25/1h-3/hostname\n",
      "Error for out/coreutils-8.25/1h-3/setuidgid\n",
      "Error for out/coreutils-8.25/1h-2/hostname\n",
      "Error for out/coreutils-8.25/1h-2/setuidgid\n",
      "Error for out/coreutils-8.25/1h/hostname\n",
      "Error for out/coreutils-8.25/1h/setuidgid\n",
      "Error for out/coreutils-9.4/1h-3/hostname\n",
      "Error for out/coreutils-9.4/1h-3/setuidgid\n",
      "Error for out/coreutils-9.4/1h-2/hostname\n",
      "Error for out/coreutils-9.4/1h-2/setuidgid\n",
      "Error for out/coreutils-9.4/1h/hostname\n",
      "Error for out/coreutils-9.4/1h/setuidgid\n"
     ]
    }
   ],
   "source": [
    "def read_num_errors(error_type:str) -> Callable[[Path], str]:\n",
    "    def f(util_path: Path) -> str:\n",
    "        file_path = util_path / \"klee\"\n",
    "        if file_path.exists():\n",
    "            return str(len(list(file_path.glob(f\"*{error_type}.err\"))))\n",
    "        else:\n",
    "            print(f\"Error for {util_path}\")\n",
    "            return None\n",
    "    return f\n",
    "error_types = [file.name for run in runs.keys() for file in list(run.glob(\"**/*.err\"))]\n",
    "error_types = [e.split(\".\")[-2] for e in error_types]\n",
    "error_types = list(set(error_types))\n",
    "for error_type in error_types:\n",
    "    add_entry_for_utils(f\"num_errors ({error_type})\", read_num_errors(error_type))\n",
    "add_entry_for_utils(f\"num_errors (total)\", read_num_errors(\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coverage according to KLEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for ICov(%) — out/coreutils-8.25/1h-3/hostname\n",
      "Error for ICov(%) — out/coreutils-8.25/1h-3/setuidgid\n",
      "Error for ICov(%) — out/coreutils-8.25/1h-2/hostname\n",
      "Error for ICov(%) — out/coreutils-8.25/1h-2/setuidgid\n",
      "Error for ICov(%) — out/coreutils-8.25/1h/hostname\n",
      "Error for ICov(%) — out/coreutils-8.25/1h/setuidgid\n",
      "Error for ICov(%) — out/coreutils-9.4/1h-3/hostname\n",
      "Error for ICov(%) — out/coreutils-9.4/1h-3/setuidgid\n",
      "Error for ICov(%) — out/coreutils-9.4/1h-2/hostname\n",
      "Error for ICov(%) — out/coreutils-9.4/1h-2/setuidgid\n",
      "Error for ICov(%) — out/coreutils-9.4/1h/hostname\n",
      "Error for ICov(%) — out/coreutils-9.4/1h/setuidgid\n",
      "Error for BCov(%) — out/coreutils-8.25/1h-3/hostname\n",
      "Error for BCov(%) — out/coreutils-8.25/1h-3/setuidgid\n",
      "Error for BCov(%) — out/coreutils-8.25/1h-2/hostname\n",
      "Error for BCov(%) — out/coreutils-8.25/1h-2/setuidgid\n",
      "Error for BCov(%) — out/coreutils-8.25/1h/hostname\n",
      "Error for BCov(%) — out/coreutils-8.25/1h/setuidgid\n",
      "Error for BCov(%) — out/coreutils-9.4/1h-3/hostname\n",
      "Error for BCov(%) — out/coreutils-9.4/1h-3/setuidgid\n",
      "Error for BCov(%) — out/coreutils-9.4/1h-2/hostname\n",
      "Error for BCov(%) — out/coreutils-9.4/1h-2/setuidgid\n",
      "Error for BCov(%) — out/coreutils-9.4/1h/hostname\n",
      "Error for BCov(%) — out/coreutils-9.4/1h/setuidgid\n"
     ]
    }
   ],
   "source": [
    "def read_klee_csv(csv_name: str) -> Callable[[Path], str]:\n",
    "    def f(util_path: Path) -> str:\n",
    "        file_path = util_path / \"klee-stats.csv\"\n",
    "        if file_path.exists() and file_path.stat().st_size > 0:\n",
    "            df = pd.read_csv(file_path)\n",
    "            return str(df[csv_name][0])\n",
    "        else:\n",
    "            print(f\"Error for {csv_name} — {util_path}\")\n",
    "            return None\n",
    "    return f\n",
    "\n",
    "add_entry_for_utils(\"klee_ICov\", read_klee_csv(\"ICov(%)\"))\n",
    "add_entry_for_utils(\"klee_BCov\", read_klee_csv(\"BCov(%)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coverage according to `gcov`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for out/coreutils-8.25/1h-3/hostname\n",
      "Error for out/coreutils-8.25/1h-3/setuidgid\n",
      "Error for out/coreutils-8.25/1h-2/hostname\n",
      "Error for out/coreutils-8.25/1h-2/setuidgid\n",
      "Error for out/coreutils-8.25/1h/hostname\n",
      "Error for out/coreutils-8.25/1h/setuidgid\n",
      "Error for out/coreutils-6.10/6h-3/uniq\n",
      "Error for out/coreutils-6.10/6h-3/who\n",
      "Error for out/coreutils-6.10/6h-3/tsort\n",
      "Error for out/coreutils-9.4/1h-3/hostname\n",
      "Error for out/coreutils-9.4/1h-3/setuidgid\n",
      "Error for out/coreutils-9.4/1h-3/cksum\n",
      "Error for out/coreutils-9.4/1h-3/wc\n",
      "Error for out/coreutils-9.4/1h-2/hostname\n",
      "Error for out/coreutils-9.4/1h-2/setuidgid\n",
      "Error for out/coreutils-9.4/1h-2/cksum\n",
      "Error for out/coreutils-9.4/1h-2/wc\n",
      "Error for out/coreutils-9.4/1h/hostname\n",
      "Error for out/coreutils-9.4/1h/setuidgid\n",
      "Error for out/coreutils-9.4/1h/cksum\n",
      "Error for out/coreutils-9.4/1h/wc\n"
     ]
    }
   ],
   "source": [
    "def read_gcov_cov(util_path: Path) -> str:\n",
    "    file_path = util_path / \"cov.txt\"\n",
    "    if file_path.exists():\n",
    "        with open(file_path, \"r\") as file:\n",
    "            res = re.search(r\"File '(\\.\\./)?\\.\\./src/(\\w+)\\.c'\\nLines executed:(\\d?\\d\\d.\\d\\d)% of \\d+\", file.read())\n",
    "            if res:\n",
    "                return res.group(3)\n",
    "    else:\n",
    "        print(f\"Error for {util_path}\")\n",
    "        return None\n",
    "\n",
    "add_entry_for_utils(\"gcov_cov\", read_gcov_cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots\n",
    "### Massaging `df`s together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       key      util  value      run     time         version\n",
      "2229              gcov_cov       tee  78.16       1h    60min  coreutils-8.25\n",
      "3117              gcov_cov        tr  80.62    24h-3  1440min  coreutils-6.10\n",
      "9953             klee_ICov       seq  47.63    10min    10min  coreutils-6.10\n",
      "9473      num_errors (ptr)       pwd   0.00    10min    10min  coreutils-6.10\n",
      "11954            klee_BCov      kill  32.44  10min-2    10min  coreutils-6.10\n",
      "4432    num_errors (total)        du   0.00      24h  1440min  coreutils-6.10\n",
      "5447             klee_BCov        cp  27.79     6h-2   360min  coreutils-6.10\n",
      "1307              gcov_cov    uptime  87.50     1h-2    60min  coreutils-8.25\n",
      "14771    num_errors (exec)     tsort   0.00       1h    60min   coreutils-9.4\n",
      "7719              gcov_cov      stty  81.14     1h-2    60min  coreutils-6.10\n",
      "6477   num_errors (solver)     users   0.00       6h   360min  coreutils-6.10\n",
      "13777   num_errors (total)    expand   1.00     1h-2    60min   coreutils-9.4\n",
      "1443    num_errors (model)       tee   0.00     1h-2    60min  coreutils-8.25\n",
      "10508   num_errors (total)     mkdir   1.00  10min-3    10min  coreutils-6.10\n",
      "530     num_errors (model)      head   1.00     1h-3    60min  coreutils-8.25\n",
      "6610     num_errors (exec)   dirname   0.00       6h   360min  coreutils-6.10\n",
      "6401    num_errors (abort)      kill   0.00       6h   360min  coreutils-6.10\n",
      "2127   num_errors (solver)  printenv   0.00       1h    60min  coreutils-8.25\n",
      "1499   num_errors (solver)       cat   0.00     1h-2    60min  coreutils-8.25\n",
      "13945   num_errors (total)      link   1.00     1h-2    60min   coreutils-9.4\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for k, v in runs.items():\n",
    "    df = v[\"df\"]\n",
    "    df = df.reset_index(names=\"key\")\n",
    "    df = df.melt(id_vars=\"key\", var_name=\"util\")\n",
    "    df[\"run\"] = k.name\n",
    "    df[\"time\"] = v[\"time\"]\n",
    "    df[\"version\"] = v[\"version\"]\n",
    "    dfs.append(df)\n",
    "\n",
    "combined_df = pd.concat(dfs)\n",
    "combined_df['value'] = combined_df['value'].astype(np.float64)\n",
    "combined_df = combined_df.dropna(subset=['value'])\n",
    "combined_df = combined_df.reset_index(drop=True)\n",
    "print(combined_df.sample(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots by coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage_df = combined_df\n",
    "versions = natsorted(coverage_df[\"version\"].unique())\n",
    "keys = natsorted(coverage_df[\"key\"].unique())\n",
    "time_categories = natsorted(coverage_df[\"time\"].unique())\n",
    "\n",
    "color_map = dict(zip(time_categories, sns.color_palette(n_colors=len(time_categories))))\n",
    "\n",
    "for key in keys:\n",
    "    key_df = coverage_df[coverage_df[\"key\"] == key].drop(columns=\"key\")\n",
    "    fig, axes = plt.subplots(\n",
    "        ncols=1,\n",
    "        nrows=len(versions),\n",
    "        figsize=(10, 5*len(versions)),\n",
    "        dpi=300,\n",
    "    )\n",
    "    fig.suptitle(f\"Empirical Cumulative Distribution Function (ECDF) for {key}\", fontsize=20, y=0.99)\n",
    "    for version_i, version in enumerate(versions):\n",
    "        version_df = key_df[key_df[\"version\"] == version].drop(columns=\"version\")\n",
    "        ax = axes[version_i]\n",
    "        ax.set_title(version)\n",
    "        for time in natsorted(version_df[\"time\"].unique()):\n",
    "            time_df = version_df[version_df[\"time\"] == time].drop(columns=\"time\")\n",
    "            for run_i, run in enumerate(time_df[\"run\"].unique()):\n",
    "                run_df = time_df[time_df[\"run\"] == run].drop(columns=\"run\")\n",
    "                sns.ecdfplot(\n",
    "                    y=\"value\",\n",
    "                    data=run_df,\n",
    "                    ax=ax,\n",
    "                    color=color_map[time],\n",
    "                    label=time if run_i == 0 else \"_nolegend_\",\n",
    "                    stat=\"count\",\n",
    "                )\n",
    "        ax.legend(title=\"Time\")\n",
    "    plt.tight_layout()\n",
    "    Path(f\"plots/{key}\").mkdir(exist_ok=True, parents=True)\n",
    "    plt.savefig(f\"plots/{key}/ecdf.png\")\n",
    "    plt.close()\n",
    "    print(f\"Done with {key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gains by time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = combined_df[combined_df[\"version\"] == \"coreutils-6.10\"].drop(\n",
    "    columns=[\"run\", \"version\"]\n",
    ")\n",
    "df = df.groupby([\"key\", \"time\", \"util\"], as_index=False).mean()\n",
    "keys = natsorted(df[\"key\"].unique())\n",
    "fig, axes = plt.subplots(nrows=len(keys), ncols=1, figsize=(5, 3 * len(keys)), dpi=300)\n",
    "for i, key in enumerate(keys):\n",
    "    df_keys = df[df[\"key\"] == key]\n",
    "    df_keys = df_keys.drop(columns=\"key\")\n",
    "    order = natsorted(df_keys[\"time\"].unique())\n",
    "    df_keys[\"time\"] = pd.Categorical(df_keys[\"time\"], categories=order, ordered=True)\n",
    "    df_keys = df_keys.sort_values([\"util\", \"time\"])\n",
    "    df_keys[\"difference\"] = df_keys.groupby(\"util\", as_index=False)[\"value\"].diff()\n",
    "    df_keys = df_keys.drop(columns=[\"util\", \"value\"])\n",
    "    df_keys = df_keys.groupby([\"time\"], as_index=False, observed=True).mean()\n",
    "    df_keys[\"time\"] = (\n",
    "        df_keys[\"time\"].shift(1).astype(str) + \" - \" + df_keys[\"time\"].astype(str)\n",
    "    )\n",
    "    df_keys = df_keys.dropna()\n",
    "    sns.barplot(data=df_keys, x=\"time\", y=\"difference\", ax=axes[i])\n",
    "    axes[i].set_ylabel(f\"average {key} gained\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"plots/gains_by_time.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots by util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with gcov_cov\n",
      "Done with klee_BCov\n",
      "Done with klee_ICov\n",
      "Done with num_errors (abort)\n",
      "Done with num_errors (exec)\n",
      "Done with num_errors (model)\n",
      "Done with num_errors (ptr)\n",
      "Done with num_errors (solver)\n",
      "Done with num_errors (total)\n"
     ]
    }
   ],
   "source": [
    "def paint_util(args):\n",
    "    key, util, key_df = args\n",
    "    util_df = key_df[key_df[\"util\"] == util].drop(columns=\"util\")\n",
    "    util_df = util_df.sort_values(by=\"version\")\n",
    "    times = natsorted(util_df['time'].unique())\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 6), dpi=300)\n",
    "    sns.stripplot(data=util_df, ax=ax, x='time', y=\"value\", hue=\"version\", order=times)\n",
    "    ax.set_title(f\"{util}\")\n",
    "    ax.set_ylabel(key)\n",
    "    fig.tight_layout()\n",
    "    Path(f\"plots/{key}/by-util\").mkdir(exist_ok=True, parents=True)\n",
    "    fig.savefig(f\"plots/{key}/by-util/{util}.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "for key in natsorted(combined_df[\"key\"].unique()):\n",
    "    key_df = combined_df[combined_df[\"key\"] == key].drop(columns=\"key\")\n",
    "    \n",
    "    utils = natsorted(key_df[\"util\"].unique())\n",
    "\n",
    "    with multiprocessing.Pool() as pool:\n",
    "        pool.map(paint_util, [(key, util, key_df) for util in utils])\n",
    "    \n",
    "    print(f\"Done with {key}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
