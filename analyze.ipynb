{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Any, Dict\n",
    "import re\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "from natsort import natsorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global information about each suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = {\n",
    "    run: {\"version\": version.name}\n",
    "    for version in Path(\"./out\").iterdir()\n",
    "    for run in version.iterdir()\n",
    "}\n",
    "\n",
    "\n",
    "def add_entry_to_run(\n",
    "    new_key: str, f: Callable[[Path, Dict[str, Any]], Any]\n",
    ") -> Dict[Path, Dict[str, Any]]:\n",
    "    global runs\n",
    "    for key, value in runs.items():\n",
    "        value.update({new_key: f(key, value)})\n",
    "\n",
    "\n",
    "add_entry_to_run(\"name\", lambda p, d: p.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time(p:Path, d):\n",
    "    file_path = p.rglob(\"klee/info\").__next__()\n",
    "    if file_path.exists():\n",
    "        with open(file_path, \"r\") as file:\n",
    "            res = re.search(r\"--max-time=(\\w*)\", file.read())\n",
    "            if res:\n",
    "                return res.group(1)\n",
    "\n",
    "    print(f\"Error for {p}\")\n",
    "    return None\n",
    "\n",
    "add_entry_to_run(\"time\", get_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per util information\n",
    "\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_entry_to_run(\"df\", lambda p, d: pd.DataFrame(columns=[e.name for e in p.iterdir() if e.is_dir()]))\n",
    "\n",
    "def add_entry_for_utils(key: str, f: Callable[[Path], Any]) -> None:\n",
    "    \"\"\"\n",
    "    Add entry for all utils\n",
    "\n",
    "    Paramenters:\n",
    "    key (str): key to add the new value at in the dataframe\n",
    "    f (Callable[[Path], Any]): function taking the path to the subfolder for the util and returning the appropriate value\n",
    "    \"\"\"\n",
    "\n",
    "    def adder(p: Path, d):\n",
    "        df = d[\"df\"]\n",
    "        res = {}\n",
    "        for util in df.columns:\n",
    "            path = p / util\n",
    "            if not path.exists():\n",
    "                raise Exception(f\"Path \\\"{util}\\\" does not exist\")\n",
    "            res[util] = f(path)\n",
    "        df.loc[key] = res\n",
    "        return df\n",
    "    add_entry_to_run(\"df\", adder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of errors according to KLEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for out/coreutils-8.25/1h-3/hostname\n",
      "Error for out/coreutils-8.25/1h-3/setuidgid\n",
      "Error for out/coreutils-8.25/1h-2/hostname\n",
      "Error for out/coreutils-8.25/1h-2/setuidgid\n",
      "Error for out/coreutils-8.25/1h/hostname\n",
      "Error for out/coreutils-8.25/1h/setuidgid\n",
      "Error for out/coreutils-9.4/1h-3/hostname\n",
      "Error for out/coreutils-9.4/1h-3/setuidgid\n",
      "Error for out/coreutils-9.4/1h-2/hostname\n",
      "Error for out/coreutils-9.4/1h-2/setuidgid\n",
      "Error for out/coreutils-9.4/1h/hostname\n",
      "Error for out/coreutils-9.4/1h/setuidgid\n",
      "Error for out/coreutils-8.25/1h-3/hostname\n",
      "Error for out/coreutils-8.25/1h-3/setuidgid\n",
      "Error for out/coreutils-8.25/1h-2/hostname\n",
      "Error for out/coreutils-8.25/1h-2/setuidgid\n",
      "Error for out/coreutils-8.25/1h/hostname\n",
      "Error for out/coreutils-8.25/1h/setuidgid\n",
      "Error for out/coreutils-9.4/1h-3/hostname\n",
      "Error for out/coreutils-9.4/1h-3/setuidgid\n",
      "Error for out/coreutils-9.4/1h-2/hostname\n",
      "Error for out/coreutils-9.4/1h-2/setuidgid\n",
      "Error for out/coreutils-9.4/1h/hostname\n",
      "Error for out/coreutils-9.4/1h/setuidgid\n",
      "Error for out/coreutils-8.25/1h-3/hostname\n",
      "Error for out/coreutils-8.25/1h-3/setuidgid\n",
      "Error for out/coreutils-8.25/1h-2/hostname\n",
      "Error for out/coreutils-8.25/1h-2/setuidgid\n",
      "Error for out/coreutils-8.25/1h/hostname\n",
      "Error for out/coreutils-8.25/1h/setuidgid\n",
      "Error for out/coreutils-9.4/1h-3/hostname\n",
      "Error for out/coreutils-9.4/1h-3/setuidgid\n",
      "Error for out/coreutils-9.4/1h-2/hostname\n",
      "Error for out/coreutils-9.4/1h-2/setuidgid\n",
      "Error for out/coreutils-9.4/1h/hostname\n",
      "Error for out/coreutils-9.4/1h/setuidgid\n",
      "Error for out/coreutils-8.25/1h-3/hostname\n",
      "Error for out/coreutils-8.25/1h-3/setuidgid\n",
      "Error for out/coreutils-8.25/1h-2/hostname\n",
      "Error for out/coreutils-8.25/1h-2/setuidgid\n",
      "Error for out/coreutils-8.25/1h/hostname\n",
      "Error for out/coreutils-8.25/1h/setuidgid\n",
      "Error for out/coreutils-9.4/1h-3/hostname\n",
      "Error for out/coreutils-9.4/1h-3/setuidgid\n",
      "Error for out/coreutils-9.4/1h-2/hostname\n",
      "Error for out/coreutils-9.4/1h-2/setuidgid\n",
      "Error for out/coreutils-9.4/1h/hostname\n",
      "Error for out/coreutils-9.4/1h/setuidgid\n",
      "Error for out/coreutils-8.25/1h-3/hostname\n",
      "Error for out/coreutils-8.25/1h-3/setuidgid\n",
      "Error for out/coreutils-8.25/1h-2/hostname\n",
      "Error for out/coreutils-8.25/1h-2/setuidgid\n",
      "Error for out/coreutils-8.25/1h/hostname\n",
      "Error for out/coreutils-8.25/1h/setuidgid\n",
      "Error for out/coreutils-9.4/1h-3/hostname\n",
      "Error for out/coreutils-9.4/1h-3/setuidgid\n",
      "Error for out/coreutils-9.4/1h-2/hostname\n",
      "Error for out/coreutils-9.4/1h-2/setuidgid\n",
      "Error for out/coreutils-9.4/1h/hostname\n",
      "Error for out/coreutils-9.4/1h/setuidgid\n",
      "Error for out/coreutils-8.25/1h-3/hostname\n",
      "Error for out/coreutils-8.25/1h-3/setuidgid\n",
      "Error for out/coreutils-8.25/1h-2/hostname\n",
      "Error for out/coreutils-8.25/1h-2/setuidgid\n",
      "Error for out/coreutils-8.25/1h/hostname\n",
      "Error for out/coreutils-8.25/1h/setuidgid\n",
      "Error for out/coreutils-9.4/1h-3/hostname\n",
      "Error for out/coreutils-9.4/1h-3/setuidgid\n",
      "Error for out/coreutils-9.4/1h-2/hostname\n",
      "Error for out/coreutils-9.4/1h-2/setuidgid\n",
      "Error for out/coreutils-9.4/1h/hostname\n",
      "Error for out/coreutils-9.4/1h/setuidgid\n"
     ]
    }
   ],
   "source": [
    "def read_num_errors(error_type:str) -> Callable[[Path], str]:\n",
    "    def f(util_path: Path) -> str:\n",
    "        file_path = util_path / \"klee\"\n",
    "        if file_path.exists():\n",
    "            return str(len(list(file_path.glob(f\"*{error_type}.err\"))))\n",
    "        else:\n",
    "            print(f\"Error for {util_path}\")\n",
    "            return None\n",
    "    return f\n",
    "error_types = [file.name for run in runs.keys() for file in list(run.glob(\"**/*.err\"))]\n",
    "error_types = [e.split(\".\")[-2] for e in error_types]\n",
    "error_types = list(set(error_types))\n",
    "for error_type in error_types:\n",
    "    add_entry_for_utils(f\"num_errors ({error_type})\", read_num_errors(error_type))\n",
    "add_entry_for_utils(f\"num_errors (total)\", read_num_errors(\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coverage according to KLEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for ICov(%) — out/coreutils-8.25/1h-3/hostname\n",
      "Error for ICov(%) — out/coreutils-8.25/1h-3/setuidgid\n",
      "Error for ICov(%) — out/coreutils-8.25/1h-2/hostname\n",
      "Error for ICov(%) — out/coreutils-8.25/1h-2/setuidgid\n",
      "Error for ICov(%) — out/coreutils-8.25/1h/hostname\n",
      "Error for ICov(%) — out/coreutils-8.25/1h/setuidgid\n",
      "Error for ICov(%) — out/coreutils-9.4/1h-3/hostname\n",
      "Error for ICov(%) — out/coreutils-9.4/1h-3/setuidgid\n",
      "Error for ICov(%) — out/coreutils-9.4/1h-2/hostname\n",
      "Error for ICov(%) — out/coreutils-9.4/1h-2/setuidgid\n",
      "Error for ICov(%) — out/coreutils-9.4/1h/hostname\n",
      "Error for ICov(%) — out/coreutils-9.4/1h/setuidgid\n",
      "Error for BCov(%) — out/coreutils-8.25/1h-3/hostname\n",
      "Error for BCov(%) — out/coreutils-8.25/1h-3/setuidgid\n",
      "Error for BCov(%) — out/coreutils-8.25/1h-2/hostname\n",
      "Error for BCov(%) — out/coreutils-8.25/1h-2/setuidgid\n",
      "Error for BCov(%) — out/coreutils-8.25/1h/hostname\n",
      "Error for BCov(%) — out/coreutils-8.25/1h/setuidgid\n",
      "Error for BCov(%) — out/coreutils-9.4/1h-3/hostname\n",
      "Error for BCov(%) — out/coreutils-9.4/1h-3/setuidgid\n",
      "Error for BCov(%) — out/coreutils-9.4/1h-2/hostname\n",
      "Error for BCov(%) — out/coreutils-9.4/1h-2/setuidgid\n",
      "Error for BCov(%) — out/coreutils-9.4/1h/hostname\n",
      "Error for BCov(%) — out/coreutils-9.4/1h/setuidgid\n"
     ]
    }
   ],
   "source": [
    "def read_klee_csv(csv_name: str) -> Callable[[Path], str]:\n",
    "    def f(util_path: Path) -> str:\n",
    "        file_path = util_path / \"klee-stats.csv\"\n",
    "        if file_path.exists() and file_path.stat().st_size > 0:\n",
    "            df = pd.read_csv(file_path)\n",
    "            return str(df[csv_name][0])\n",
    "        else:\n",
    "            print(f\"Error for {csv_name} — {util_path}\")\n",
    "            return None\n",
    "    return f\n",
    "\n",
    "add_entry_for_utils(\"klee_ICov\", read_klee_csv(\"ICov(%)\"))\n",
    "add_entry_for_utils(\"klee_BCov\", read_klee_csv(\"BCov(%)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coverage according to `gcov`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for out/coreutils-8.25/1h-3/hostname\n",
      "Error for out/coreutils-8.25/1h-3/[\n",
      "Error for out/coreutils-8.25/1h-3/base64\n",
      "Error for out/coreutils-8.25/1h-3/setuidgid\n",
      "Error for out/coreutils-8.25/1h-3/md5sum\n",
      "Error for out/coreutils-8.25/1h-3/ginstall\n",
      "Error for out/coreutils-8.25/1h-2/hostname\n",
      "Error for out/coreutils-8.25/1h-2/[\n",
      "Error for out/coreutils-8.25/1h-2/base64\n",
      "Error for out/coreutils-8.25/1h-2/setuidgid\n",
      "Error for out/coreutils-8.25/1h-2/md5sum\n",
      "Error for out/coreutils-8.25/1h-2/ginstall\n",
      "Error for out/coreutils-8.25/1h/hostname\n",
      "Error for out/coreutils-8.25/1h/[\n",
      "Error for out/coreutils-8.25/1h/base64\n",
      "Error for out/coreutils-8.25/1h/setuidgid\n",
      "Error for out/coreutils-8.25/1h/md5sum\n",
      "Error for out/coreutils-8.25/1h/ginstall\n",
      "Error for out/coreutils-6.10/24h-3/md5sum\n",
      "Error for out/coreutils-6.10/24h-3/ginstall\n",
      "Error for out/coreutils-6.10/6h-3/uniq\n",
      "Error for out/coreutils-6.10/6h-3/who\n",
      "Error for out/coreutils-6.10/6h-3/md5sum\n",
      "Error for out/coreutils-6.10/6h-3/tsort\n",
      "Error for out/coreutils-6.10/6h-3/ginstall\n",
      "Error for out/coreutils-6.10/24h/md5sum\n",
      "Error for out/coreutils-6.10/24h/ginstall\n",
      "Error for out/coreutils-6.10/6h-2/md5sum\n",
      "Error for out/coreutils-6.10/6h-2/ginstall\n",
      "Error for out/coreutils-6.10/1h-3/md5sum\n",
      "Error for out/coreutils-6.10/1h-3/ginstall\n",
      "Error for out/coreutils-6.10/6h/md5sum\n",
      "Error for out/coreutils-6.10/6h/ginstall\n",
      "Error for out/coreutils-6.10/1h-2/[\n",
      "Error for out/coreutils-6.10/1h-2/md5sum\n",
      "Error for out/coreutils-6.10/1h-2/ginstall\n",
      "Error for out/coreutils-6.10/1h-4/md5sum\n",
      "Error for out/coreutils-6.10/1h-4/ginstall\n",
      "Error for out/coreutils-6.10/24h-2/md5sum\n",
      "Error for out/coreutils-6.10/24h-2/ginstall\n",
      "Error for out/coreutils-6.10/10min/md5sum\n",
      "Error for out/coreutils-6.10/10min/ginstall\n",
      "Error for out/coreutils-6.10/10min-3/md5sum\n",
      "Error for out/coreutils-6.10/10min-3/ginstall\n",
      "Error for out/coreutils-6.10/1h/[\n",
      "Error for out/coreutils-6.10/1h/md5sum\n",
      "Error for out/coreutils-6.10/1h/ginstall\n",
      "Error for out/coreutils-6.10/10min-2/md5sum\n",
      "Error for out/coreutils-6.10/10min-2/ginstall\n",
      "Error for out/coreutils-9.4/1h-3/hostname\n",
      "Error for out/coreutils-9.4/1h-3/[\n",
      "Error for out/coreutils-9.4/1h-3/sum\n",
      "Error for out/coreutils-9.4/1h-3/base64\n",
      "Error for out/coreutils-9.4/1h-3/setuidgid\n",
      "Error for out/coreutils-9.4/1h-3/cksum\n",
      "Error for out/coreutils-9.4/1h-3/wc\n",
      "Error for out/coreutils-9.4/1h-3/md5sum\n",
      "Error for out/coreutils-9.4/1h-3/ginstall\n",
      "Error for out/coreutils-9.4/1h-2/hostname\n",
      "Error for out/coreutils-9.4/1h-2/[\n",
      "Error for out/coreutils-9.4/1h-2/sum\n",
      "Error for out/coreutils-9.4/1h-2/base64\n",
      "Error for out/coreutils-9.4/1h-2/setuidgid\n",
      "Error for out/coreutils-9.4/1h-2/cksum\n",
      "Error for out/coreutils-9.4/1h-2/wc\n",
      "Error for out/coreutils-9.4/1h-2/md5sum\n",
      "Error for out/coreutils-9.4/1h-2/ginstall\n",
      "Error for out/coreutils-9.4/1h/hostname\n",
      "Error for out/coreutils-9.4/1h/[\n",
      "Error for out/coreutils-9.4/1h/sum\n",
      "Error for out/coreutils-9.4/1h/base64\n",
      "Error for out/coreutils-9.4/1h/setuidgid\n",
      "Error for out/coreutils-9.4/1h/cksum\n",
      "Error for out/coreutils-9.4/1h/wc\n",
      "Error for out/coreutils-9.4/1h/md5sum\n",
      "Error for out/coreutils-9.4/1h/ginstall\n"
     ]
    }
   ],
   "source": [
    "def read_gcov_cov(util_path: Path) -> str:\n",
    "    file_path = util_path / \"cov.txt\"\n",
    "    if file_path.exists():\n",
    "        with open(file_path, \"r\") as file:\n",
    "            res = re.search(r\"File '(\\.\\./)?\\.\\./src/(\\w+)\\.c'\\nLines executed:(\\d?\\d\\d.\\d\\d)% of \\d+\", file.read())\n",
    "            if res:\n",
    "                return res.group(3)\n",
    "    print(f\"Error for {util_path}\")\n",
    "    return None\n",
    "\n",
    "add_entry_for_utils(\"gcov_cov\", read_gcov_cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots\n",
    "### Massaging `df`s together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    key    util  value      run     time  \\\n",
      "5026        coverage: branch (KLEE) (%)      id  29.62     6h-2   360min   \n",
      "2994               error count: pointer   chgrp   0.00    24h-3  1440min   \n",
      "11166               error count: solver    sort   0.00       1h    60min   \n",
      "833                 error count: solver  unlink   0.00     1h-2    60min   \n",
      "13967               error count: solver  printf   0.00     1h-2    60min   \n",
      "6168                error count: solver     tee   0.00     1h-3    60min   \n",
      "10532                error count: abort  mkfifo   0.00  10min-3    10min   \n",
      "2318          coverage: line (gcov) (%)    expr  89.91       1h    60min   \n",
      "3421   coverage: instruction (KLEE) (%)  mkfifo  41.42     6h-3   360min   \n",
      "10716  coverage: instruction (KLEE) (%)   cksum  42.54  10min-3    10min   \n",
      "12541                error count: abort   false   0.00  10min-2    10min   \n",
      "4921               error count: pointer    stat   0.00     6h-2   360min   \n",
      "13787  coverage: instruction (KLEE) (%)  runcon  42.21     1h-2    60min   \n",
      "4710   coverage: instruction (KLEE) (%)      ln  43.24     6h-2   360min   \n",
      "5631                 error count: abort     cut   0.00     1h-3    60min   \n",
      "2587        coverage: branch (KLEE) (%)      df  40.44    24h-3  1440min   \n",
      "9402                  error count: exec      cp   0.00    24h-2  1440min   \n",
      "1023                 error count: abort      df   0.00     1h-2    60min   \n",
      "1526                  error count: exec    shuf   0.00     1h-2    60min   \n",
      "10521               error count: solver     sum   0.00  10min-3    10min   \n",
      "\n",
      "              version  \n",
      "5026   coreutils-6.10  \n",
      "2994   coreutils-6.10  \n",
      "11166  coreutils-6.10  \n",
      "833    coreutils-8.25  \n",
      "13967   coreutils-9.4  \n",
      "6168   coreutils-6.10  \n",
      "10532  coreutils-6.10  \n",
      "2318   coreutils-8.25  \n",
      "3421   coreutils-6.10  \n",
      "10716  coreutils-6.10  \n",
      "12541  coreutils-6.10  \n",
      "4921   coreutils-6.10  \n",
      "13787   coreutils-9.4  \n",
      "4710   coreutils-6.10  \n",
      "5631   coreutils-6.10  \n",
      "2587   coreutils-6.10  \n",
      "9402   coreutils-6.10  \n",
      "1023   coreutils-8.25  \n",
      "1526   coreutils-8.25  \n",
      "10521  coreutils-6.10  \n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for k, v in runs.items():\n",
    "    df = v[\"df\"]\n",
    "    df = df.reset_index(names=\"key\")\n",
    "    df = df.melt(id_vars=\"key\", var_name=\"util\")\n",
    "    df[\"run\"] = k.name\n",
    "    df[\"time\"] = v[\"time\"]\n",
    "    df[\"version\"] = v[\"version\"]\n",
    "    dfs.append(df)\n",
    "\n",
    "combined_df = pd.concat(dfs)\n",
    "combined_df['value'] = combined_df['value'].astype(np.float64)\n",
    "combined_df = combined_df.dropna(subset=['value'])\n",
    "combined_df = combined_df.reset_index(drop=True)\n",
    "keys_nat = {\n",
    "    \"gcov_cov\": \"coverage: line (gcov) (%)\",\n",
    "    \"klee_ICov\": \"coverage: instruction (KLEE) (%)\",\n",
    "    \"klee_BCov\": \"coverage: branch (KLEE) (%)\",\n",
    "    \"num_errors (abort)\": \"error count: abort\",\n",
    "    \"num_errors (exec)\": \"error count: exec\",\n",
    "    \"num_errors (model)\": \"error count: model\",\n",
    "    \"num_errors (ptr)\": \"error count: pointer\",\n",
    "    \"num_errors (solver)\": \"error count: solver\",\n",
    "    \"num_errors (total)\": \"error count: total\",\n",
    "}\n",
    "\n",
    "path_by_key = {v:k for k,v in keys_nat.items()}\n",
    "\n",
    "combined_df = combined_df.copy(deep=True)\n",
    "combined_df[\"key\"] = combined_df[\"key\"].map(keys_nat)\n",
    "print(combined_df.sample(20))\n",
    "\n",
    "dpi = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots by coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paint_util(args):\n",
    "    key, key_df = args\n",
    "\n",
    "    path = f\"plots/{path_by_key[key]}\"\n",
    "    Path(path).mkdir(exist_ok=True, parents=True)\n",
    "    # By version\n",
    "    fixed_time_df = key_df[key_df[\"time\"] == \"60min\"].drop(columns=\"time\")\n",
    "    versions = natsorted(fixed_time_df[\"version\"].unique())\n",
    "    fig, axes = plt.subplots(\n",
    "        ncols=1,\n",
    "        nrows=len(versions),\n",
    "        figsize=(6, 3 * len(versions)),\n",
    "        dpi=dpi,\n",
    "    )\n",
    "    for version_i, version in enumerate(versions):\n",
    "        version_df = fixed_time_df[fixed_time_df[\"version\"] == version].drop(\n",
    "            columns=\"version\"\n",
    "        )\n",
    "        ax = axes[version_i]\n",
    "        ax.set_title(version)\n",
    "        for run in version_df[\"run\"].unique():\n",
    "            run_df = version_df[version_df[\"run\"] == run].drop(columns=\"run\")\n",
    "            sns.ecdfplot(\n",
    "                y=\"value\",\n",
    "                data=run_df,\n",
    "                ax=ax,\n",
    "                stat=\"count\",\n",
    "            )\n",
    "        ax.set_ylim(ymin=0)\n",
    "        ax.set_ylabel(key)\n",
    "        ax.set_xlabel(None)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(path + \"/ecdf_by_version.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    # By time\n",
    "    fixed_version_df = key_df[key_df[\"version\"] == \"coreutils-6.10\"].drop(columns=\"version\")\n",
    "    times = natsorted(fixed_version_df[\"time\"].unique())\n",
    "    fig, axes = plt.subplots(\n",
    "        ncols=2,\n",
    "        nrows=len(times) // 2,\n",
    "        figsize=(6 * 2, 3 * len(times) // 2),\n",
    "        dpi=dpi,\n",
    "    )\n",
    "\n",
    "    axes = axes.flatten()\n",
    "    for time_i, time in enumerate(times):\n",
    "        time_df = fixed_version_df[fixed_version_df[\"time\"] == time].drop(\n",
    "            columns=\"time\"\n",
    "        )\n",
    "\n",
    "        ax = axes[time_i]\n",
    "        ax.set_title(time)\n",
    "        for run in time_df[\"run\"].unique():\n",
    "            run_df = time_df[time_df[\"run\"] == run].drop(columns=\"run\")\n",
    "            sns.ecdfplot(\n",
    "                y=\"value\",\n",
    "                data=run_df,\n",
    "                ax=ax,\n",
    "                stat=\"count\",\n",
    "            )\n",
    "        ax.set_ylim(ymin=0)\n",
    "        ax.set_ylabel(key)\n",
    "        ax.set_xlabel(None)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(path + \"/ecdf_by_time.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "with multiprocessing.Pool() as pool:\n",
    "    df = combined_df.copy(deep=True)\n",
    "    pool.map(\n",
    "        paint_util,\n",
    "        [\n",
    "            (key, df[df[\"key\"] == key].drop(columns=\"key\"))\n",
    "            for key in natsorted(df[\"key\"].unique())\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gains by time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = combined_df.copy(deep=True)\n",
    "df = df[df[\"version\"] == \"coreutils-6.10\"].drop(columns=[\"run\", \"version\"])\n",
    "df = df.groupby([\"key\", \"time\", \"util\"], as_index=False).mean()\n",
    "keys = natsorted(df[\"key\"].unique())\n",
    "fig, axes = plt.subplots(nrows=len(keys), ncols=1, figsize=(5, 3 * len(keys)), dpi=dpi)\n",
    "for i, key in enumerate(keys):\n",
    "    df_keys = df[df[\"key\"] == key]\n",
    "    df_keys = df_keys.drop(columns=\"key\")\n",
    "    order = natsorted(df_keys[\"time\"].unique())\n",
    "    df_keys[\"time\"] = pd.Categorical(df_keys[\"time\"], categories=order, ordered=True)\n",
    "    df_keys = df_keys.sort_values([\"util\", \"time\"])\n",
    "    df_keys[\"difference\"] = df_keys.groupby(\"util\", as_index=False)[\"value\"].diff()\n",
    "    df_keys = df_keys.drop(columns=[\"util\", \"value\"])\n",
    "    df_keys = df_keys.groupby([\"time\"], as_index=False, observed=True).mean()\n",
    "    df_keys[\"time\"] = (\n",
    "        df_keys[\"time\"].shift(1).astype(str) + \" - \" + df_keys[\"time\"].astype(str)\n",
    "    )\n",
    "    df_keys = df_keys.dropna()\n",
    "    sns.barplot(data=df_keys, x=\"time\", y=\"difference\", ax=axes[i])\n",
    "    axes[i].set_ylabel(f\"average {key} gained\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"plots/gains_by_time.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots by util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_stripplot = {\n",
    "    # \"alpha\": 0.5,\n",
    "    \"size\": 2,\n",
    "    \"y\": \"value_norm\",\n",
    "    \"jitter\": 0.3,\n",
    "}\n",
    "args_pointplot = {\n",
    "    \"y\": \"value_norm\",\n",
    "    \"color\": \"red\",\n",
    "    \"markers\": \"_\",\n",
    "    \"markersize\": 100,\n",
    "    \"markeredgewidth\": 1,\n",
    "    \"linestyles\": \"none\",\n",
    "    \"zorder\": 10,\n",
    "}\n",
    "\n",
    "handles = [\n",
    "    plt.Line2D(\n",
    "        [], [], linestyle=\"none\", marker=\"o\", markersize=2, color=\"blue\", label=\"values\"\n",
    "    ),\n",
    "    plt.Line2D([], [], color=\"red\", label=\"average\"),\n",
    "]\n",
    "\n",
    "\n",
    "def paint_util(args):\n",
    "    key, df = args\n",
    "    df_norm = df[(df[\"time\"] == \"60min\") & (df[\"version\"] == \"coreutils-6.10\")]\n",
    "    df_norm = df_norm.drop(columns=[\"time\", \"version\", \"run\"])\n",
    "    df_norm = df_norm.groupby(by=\"util\", as_index=False, observed=True)[\"value\"].mean()\n",
    "    df_norm = df_norm.rename(columns={\"value\": \"value_avg\"})\n",
    "    df = df.merge(df_norm, on=\"util\", how=\"left\")\n",
    "    df[\"value_norm\"] = df[\"value\"] - df[\"value_avg\"]\n",
    "    df_version = df[df[\"version\"] == \"coreutils-6.10\"]\n",
    "    df_time = df[df[\"time\"] == \"60min\"]\n",
    "    times = natsorted(df[\"time\"].unique())\n",
    "    versions = natsorted(df[\"version\"].unique())\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 4), dpi=dpi)\n",
    "\n",
    "    def get_avg(df_to_average: pd.DataFrame, key: str) -> pd.DataFrame:\n",
    "        return (\n",
    "            df_to_average[[key, \"value_norm\"]]\n",
    "            .groupby(key, as_index=False, observed=True)[\"value_norm\"]\n",
    "            .mean()\n",
    "        )\n",
    "\n",
    "    sns.stripplot(data=df_version, ax=ax, x=\"time\", order=times, **args_stripplot)\n",
    "    sns.pointplot(\n",
    "        data=get_avg(df_version, \"time\"),\n",
    "        ax=ax,\n",
    "        x=\"time\",\n",
    "        order=times,\n",
    "        **args_pointplot,\n",
    "    )\n",
    "\n",
    "    ax.set_ylabel(u'Δ '+key)\n",
    "    ax.legend(handles=handles)\n",
    "    fig.tight_layout()\n",
    "    path = f\"plots/{path_by_key[key]}\"\n",
    "    Path(path).mkdir(exist_ok=True, parents=True)\n",
    "    fig.savefig(path+\"/changes-by-time.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 4), dpi=dpi)\n",
    "\n",
    "    sns.stripplot(data=df_time, ax=ax, x=\"version\", order=versions, **args_stripplot)\n",
    "    sns.pointplot(\n",
    "        data=get_avg(df_time, \"version\"),\n",
    "        ax=ax,\n",
    "        x=\"version\",\n",
    "        order=versions,\n",
    "        **args_pointplot,\n",
    "    )\n",
    "    ax.set_ylabel(u'Δ '+key)\n",
    "    ax.legend(handles=handles)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(path+\"/changes-by-version.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "with multiprocessing.Pool() as pool:\n",
    "    df = combined_df.copy(deep=True)\n",
    "    pool.map(\n",
    "        paint_util,\n",
    "        [\n",
    "            (key, df[df[\"key\"] == key].drop(columns=\"key\"))\n",
    "            for key in natsorted(df[\"key\"].unique())\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with coverage: branch (KLEE) (%)\n",
      "Done with coverage: instruction (KLEE) (%)\n",
      "Done with coverage: line (gcov) (%)\n",
      "Done with error count: abort\n",
      "Done with error count: exec\n",
      "Done with error count: model\n",
      "Done with error count: pointer\n",
      "Done with error count: solver\n",
      "Done with error count: total\n"
     ]
    }
   ],
   "source": [
    "def paint_util(args):\n",
    "    key, util, key_df = args\n",
    "    util_df = key_df[key_df[\"util\"] == util].drop(columns=\"util\")\n",
    "    util_df = util_df.sort_values(by=\"version\")\n",
    "    times = natsorted(util_df['time'].unique())\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 6), dpi=dpi)\n",
    "    sns.stripplot(data=util_df, ax=ax, x='time', y=\"value\", hue=\"version\", order=times)\n",
    "    ax.set_title(f\"{util}\")\n",
    "    ax.set_ylabel(key)\n",
    "    fig.tight_layout()\n",
    "    path = f\"plots/{path_by_key[key]}/by-util\"\n",
    "    Path(path).mkdir(exist_ok=True, parents=True)\n",
    "    fig.savefig(path + f\"/{util}.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "df = combined_df.copy(deep=True)\n",
    "for key in natsorted(df[\"key\"].unique()):\n",
    "    key_df = df[df[\"key\"] == key].drop(columns=\"key\")\n",
    "    \n",
    "    utils = natsorted(key_df[\"util\"].unique())\n",
    "\n",
    "    with multiprocessing.Pool() as pool:\n",
    "        pool.map(paint_util, [(key, util, key_df) for util in utils])\n",
    "    \n",
    "    print(f\"Done with {key}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots for the Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### coreutils 6.10 @60min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = combined_df.copy(deep=True)\n",
    "\n",
    "c6_60_df = df[(df[\"version\"] == \"coreutils-6.10\") & (df[\"time\"] == \"60min\")].drop(\n",
    "    columns=[\"version\", \"time\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spreads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coverage: branch (KLEE) (%) 0.37\n",
      "coverage: instruction (KLEE) (%) 0.48\n",
      "coverage: line (gcov) (%) 1.56\n",
      "error count: abort 0.0\n",
      "error count: exec 0.0\n",
      "error count: model 0.1\n",
      "error count: pointer 0.33\n",
      "error count: solver 0.11\n"
     ]
    }
   ],
   "source": [
    "df = c6_60_df.copy(deep=True)\n",
    "averages = df.groupby(by=[\"util\", \"key\"], as_index=False, observed=True)\n",
    "averages = averages[\"value\"].mean()\n",
    "averages = averages.rename(columns={\"value\": \"value_avg\"})\n",
    "df = df.merge(averages, on=[\"util\", \"key\"], how=\"left\")\n",
    "df[\"value_norm\"] = df[\"value\"] - df[\"value_avg\"]\n",
    "keys = natsorted(df[\"key\"].unique())\n",
    "keys = [key for key in keys if \"total\" not in key]\n",
    "ncols = np.ceil(len(keys) / 2).astype(int)\n",
    "fig, ax = plt.subplots(2, ncols, figsize=(3 * ncols, 6 * 2), dpi=dpi)\n",
    "ax = ax.flatten()\n",
    "for i, key in enumerate(keys):\n",
    "    key_df = df[df[\"key\"] == key].drop(columns=\"key\")\n",
    "    sns.stripplot(data=key_df, ax=ax[i], **args_stripplot)\n",
    "    print(key, np.round(key_df[\"value_norm\"].std(),2))\n",
    "    ax[i].set_ylabel(None)\n",
    "    ax[i].set_xlabel(u'Δ '+key)\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"./report/assets/spread_60min_6.10.png\")\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = c6_60_df.copy(deep=True)\n",
    "df = df[df['key'] == 'coverage: line (gcov) (%)']\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4.5, 3), dpi=2*dpi)\n",
    "for run in df[\"run\"].unique():\n",
    "    sns.ecdfplot(\n",
    "        y=\"value\",\n",
    "        data=df[df[\"run\"] == run],\n",
    "        ax=ax,\n",
    "        stat=\"count\",\n",
    "    )\n",
    "ax.set_ylim(ymin=0)\n",
    "ax.set_ylabel('coverage: line (gcov) (%)')\n",
    "ax.set_xlabel(None)\n",
    "fig.tight_layout()\n",
    "fig.savefig('./report/assets/ecdf_60min_6.10.png')\n",
    "plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
